{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# from tensorflow_core.python.keras.models import Sequential\n",
    "from tensorflow_core.python.keras.layers import Dense, Dropout\n",
    "from tensorflow_core.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow_core.python.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# from tensorflow_core.python.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from keras.utils import np_utils\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow_core.python.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Load training data...\n",
      "      y\n",
      "id     \n",
      "586   1\n",
      "3508  1\n",
      "2486  2\n",
      "2181  2\n",
      "526   1\n",
      "...  ..\n",
      "1909  2\n",
      "929   1\n",
      "3211  1\n",
      "3033  1\n",
      "3424  1\n",
      "\n",
      "[3840 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "print('Load training data...')\n",
    "df_x_train = pd.read_csv('X_train.csv', header=0, index_col = 0)\n",
    "df_y_train = pd.read_csv('y_train.csv', header=0, index_col = 0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x_train, df_y_train, test_size=0.2,stratify = df_y_train['y'])\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into training and validation dataset\n",
      "Load testing data...\n",
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "scaler_norm = MinMaxScaler(feature_range=(-1,1))\n",
    "scaler_std = StandardScaler()\n",
    "\n",
    "print('Splitting into training and validation dataset')\n",
    "X_train = x_train.values\n",
    "Y_train = y_train['y'].values\n",
    "X_val = x_test.values\n",
    "Y_val = y_test['y'].values\n",
    "\n",
    "X_train = scaler_std.fit_transform(X_train)\n",
    "X_val = scaler_std.fit_transform(X_val)\n",
    "\n",
    "X_train = scaler_norm.fit_transform(X_train)\n",
    "X_val = scaler_norm.fit_transform(X_val)\n",
    "\n",
    "cls_weights = class_weight.compute_class_weight('balanced', np.unique(Y_train), \n",
    "                                                Y_train)\n",
    "cls_weight_dict = {0: cls_weights[0], 1: cls_weights[1], 2: cls_weights[2]}\n",
    "val_sample_weights = class_weight.compute_sample_weight(cls_weight_dict, Y_val)\n",
    "\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_val = to_categorical(Y_val)\n",
    "\n",
    "print('Load testing data...')\n",
    "df_x_test = pd.read_csv('X_test.csv', header=0, index_col = 0)\n",
    "X_test = df_x_test.values\n",
    "\n",
    "X_test = scaler_std.fit_transform(X_test)\n",
    "\n",
    "X_test = scaler_norm.fit_transform(X_test)\n",
    "\n",
    "\n",
    "print(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect 59 outliers in training set!\n"
     ]
    }
   ],
   "source": [
    "# remove outliers\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "def outlier_detection(x_train, y_train, method='isoforest'):\n",
    "    if(method == 'isoforest'):\n",
    "#         rng = np.random.RandomState(42)\n",
    "        clf = IsolationForest(behaviour='new', max_samples=2000,\n",
    "#                           random_state=rng, \n",
    "                              contamination='auto')\n",
    "        clf.fit(x_train)\n",
    "        indicator = clf.predict(x_train)\n",
    "        index = np.where(indicator == -1)[0]\n",
    "        print(\"detect %d outliers in training set!\" % (index.shape[0]))\n",
    "\n",
    "        x_train_clean = np.delete(x_train, index, axis=0)\n",
    "        y_train_clean = np.delete(y_train, index, axis=0)\n",
    "\n",
    "        return x_train_clean, y_train_clean\n",
    "    \n",
    "    elif(method == 'lof'):\n",
    "        clf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "        clf.fit(x_train)\n",
    "        indicator = clf.fit_predict(x_train)\n",
    "        index = np.where(indicator == -1)[0]\n",
    "        print(\"detect %d outliers in training set!\" % (index.shape[0]))\n",
    "\n",
    "        x_train_clean = np.delete(x_train, index, axis=0)\n",
    "        y_train_clean = np.delete(y_train, index, axis=0)\n",
    "        return x_train_clean,y_train_clean\n",
    "    \n",
    "\n",
    "X_train,Y_train = outlier_detection(X_train,Y_train,method='isoforest')\n",
    "# X_train,Y_train = outlier_detection(X_train,Y_train,method='lof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# # encode class values as integers\n",
    "# encoder = LabelEncoder()\n",
    "# encoder.fit(y)\n",
    "# encoded_Y = encoder.transform(y)\n",
    "# # convert integers to dummy variables (i.e. one hot encoded)\n",
    "# dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "# onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "# x = onehotencoder.fit_transform(x).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "def create_model(activation1='relu',activation2='sigmoid',d=0.5,n1=1024,n2=1512,n3=1512,n4=1024,n5=768,n6=256,n7=3):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n1, input_dim=1000, activation='relu'))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Dense(n2, activation=activation1))\n",
    "    model.add(Dense(n3, activation=activation1))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Dense(n4, activation=activation1))\n",
    "    model.add(Dense(n5, activation=activation1))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Dense(n6, activation=activation1))\n",
    "    model.add(Dense(n7, activation=activation2))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3781 samples, validate on 960 samples\n",
      "Epoch 1/200\n",
      "3781/3781 [==============================] - 3s 757us/sample - loss: 0.6414 - accuracy: 0.7286 - val_loss: 0.9315 - val_accuracy: 0.7292\n",
      "Epoch 2/200\n",
      "3781/3781 [==============================] - 2s 455us/sample - loss: 0.5226 - accuracy: 0.7762 - val_loss: 0.8643 - val_accuracy: 0.6479\n",
      "Epoch 3/200\n",
      "3781/3781 [==============================] - 2s 429us/sample - loss: 0.5147 - accuracy: 0.7797 - val_loss: 0.8443 - val_accuracy: 0.6687\n",
      "Epoch 4/200\n",
      "3781/3781 [==============================] - 2s 444us/sample - loss: 0.5148 - accuracy: 0.7778 - val_loss: 0.8609 - val_accuracy: 0.6396\n",
      "Epoch 5/200\n",
      "3781/3781 [==============================] - 2s 575us/sample - loss: 0.4883 - accuracy: 0.7903 - val_loss: 0.7927 - val_accuracy: 0.7073\n",
      "Epoch 6/200\n",
      "3781/3781 [==============================] - 2s 484us/sample - loss: 0.4612 - accuracy: 0.7985 - val_loss: 0.9312 - val_accuracy: 0.6490\n",
      "Epoch 7/200\n",
      "3781/3781 [==============================] - 2s 530us/sample - loss: 0.4648 - accuracy: 0.8011 - val_loss: 0.7816 - val_accuracy: 0.6010\n",
      "Epoch 8/200\n",
      "3781/3781 [==============================] - 2s 456us/sample - loss: 0.4456 - accuracy: 0.8133 - val_loss: 0.7799 - val_accuracy: 0.7458\n",
      "Epoch 9/200\n",
      "3781/3781 [==============================] - 2s 479us/sample - loss: 0.4418 - accuracy: 0.8135 - val_loss: 0.8667 - val_accuracy: 0.6135\n",
      "Epoch 10/200\n",
      "3781/3781 [==============================] - 2s 483us/sample - loss: 0.4164 - accuracy: 0.8268 - val_loss: 0.7368 - val_accuracy: 0.7094\n",
      "Epoch 11/200\n",
      "3781/3781 [==============================] - 2s 450us/sample - loss: 0.3918 - accuracy: 0.8392 - val_loss: 0.7418 - val_accuracy: 0.7094\n",
      "Epoch 12/200\n",
      "3781/3781 [==============================] - 2s 451us/sample - loss: 0.3913 - accuracy: 0.8326 - val_loss: 0.7241 - val_accuracy: 0.6583\n",
      "Epoch 13/200\n",
      "3781/3781 [==============================] - 1s 397us/sample - loss: 0.3956 - accuracy: 0.8442 - val_loss: 0.7570 - val_accuracy: 0.6865\n",
      "Epoch 14/200\n",
      "3781/3781 [==============================] - 2s 440us/sample - loss: 0.3640 - accuracy: 0.8471 - val_loss: 0.7870 - val_accuracy: 0.6490\n",
      "Epoch 15/200\n",
      "3781/3781 [==============================] - 2s 423us/sample - loss: 0.3762 - accuracy: 0.8479 - val_loss: 0.9519 - val_accuracy: 0.6417\n",
      "Epoch 16/200\n",
      "3781/3781 [==============================] - 2s 459us/sample - loss: 0.3976 - accuracy: 0.8482 - val_loss: 0.7906 - val_accuracy: 0.6854\n",
      "Epoch 17/200\n",
      "3781/3781 [==============================] - 2s 418us/sample - loss: 0.3622 - accuracy: 0.8572 - val_loss: 0.8444 - val_accuracy: 0.6823\n",
      "Epoch 18/200\n",
      "3781/3781 [==============================] - 2s 420us/sample - loss: 0.3635 - accuracy: 0.8482 - val_loss: 0.8075 - val_accuracy: 0.6115\n",
      "Epoch 19/200\n",
      "3781/3781 [==============================] - 2s 478us/sample - loss: 0.3343 - accuracy: 0.8604 - val_loss: 0.8389 - val_accuracy: 0.6979\n",
      "Epoch 20/200\n",
      "3781/3781 [==============================] - 2s 475us/sample - loss: 0.3218 - accuracy: 0.8654 - val_loss: 0.8266 - val_accuracy: 0.6417\n",
      "Epoch 21/200\n",
      "3781/3781 [==============================] - 2s 454us/sample - loss: 0.3209 - accuracy: 0.8646 - val_loss: 0.9171 - val_accuracy: 0.7073\n",
      "Epoch 22/200\n",
      "3781/3781 [==============================] - 2s 490us/sample - loss: 0.3307 - accuracy: 0.8680 - val_loss: 0.8298 - val_accuracy: 0.6760\n",
      "Epoch 23/200\n",
      "3781/3781 [==============================] - 2s 481us/sample - loss: 0.3273 - accuracy: 0.8688 - val_loss: 0.8599 - val_accuracy: 0.7010\n",
      "Epoch 24/200\n",
      "3781/3781 [==============================] - 2s 475us/sample - loss: 0.3143 - accuracy: 0.8686 - val_loss: 0.9180 - val_accuracy: 0.6219\n",
      "Epoch 25/200\n",
      "3781/3781 [==============================] - 2s 459us/sample - loss: 0.3346 - accuracy: 0.8667 - val_loss: 0.8126 - val_accuracy: 0.7385\n",
      "Epoch 26/200\n",
      "3781/3781 [==============================] - 2s 461us/sample - loss: 0.3383 - accuracy: 0.8609 - val_loss: 0.8622 - val_accuracy: 0.6938\n",
      "Epoch 27/200\n",
      "3781/3781 [==============================] - 2s 492us/sample - loss: 0.2962 - accuracy: 0.8794 - val_loss: 1.0656 - val_accuracy: 0.6760\n",
      "Epoch 28/200\n",
      "3781/3781 [==============================] - 2s 503us/sample - loss: 0.2979 - accuracy: 0.8765 - val_loss: 0.8421 - val_accuracy: 0.6500\n",
      "Epoch 29/200\n",
      "3781/3781 [==============================] - 2s 474us/sample - loss: 0.2962 - accuracy: 0.8757 - val_loss: 0.9423 - val_accuracy: 0.7052\n",
      "Epoch 30/200\n",
      "3781/3781 [==============================] - 2s 476us/sample - loss: 0.2862 - accuracy: 0.8889 - val_loss: 0.8766 - val_accuracy: 0.6573\n",
      "Epoch 31/200\n",
      "3781/3781 [==============================] - 2s 488us/sample - loss: 0.2927 - accuracy: 0.8783 - val_loss: 0.9957 - val_accuracy: 0.6885\n",
      "Epoch 32/200\n",
      "3781/3781 [==============================] - 2s 501us/sample - loss: 0.3143 - accuracy: 0.8715 - val_loss: 0.9700 - val_accuracy: 0.6344\n",
      "Epoch 33/200\n",
      "3781/3781 [==============================] - 2s 517us/sample - loss: 0.2974 - accuracy: 0.8781 - val_loss: 0.9129 - val_accuracy: 0.6521\n",
      "Epoch 34/200\n",
      "3781/3781 [==============================] - 2s 505us/sample - loss: 0.2901 - accuracy: 0.8805 - val_loss: 1.0317 - val_accuracy: 0.6302\n",
      "Epoch 35/200\n",
      "3781/3781 [==============================] - 2s 417us/sample - loss: 0.3032 - accuracy: 0.8725 - val_loss: 0.8737 - val_accuracy: 0.6698\n",
      "Epoch 36/200\n",
      "3781/3781 [==============================] - 2s 480us/sample - loss: 0.2927 - accuracy: 0.8752 - val_loss: 0.8450 - val_accuracy: 0.6896\n",
      "Epoch 37/200\n",
      "3781/3781 [==============================] - 2s 505us/sample - loss: 0.2858 - accuracy: 0.8802 - val_loss: 0.9762 - val_accuracy: 0.6906\n",
      "Epoch 38/200\n",
      "3781/3781 [==============================] - 2s 470us/sample - loss: 0.2717 - accuracy: 0.8892 - val_loss: 0.9260 - val_accuracy: 0.6833\n",
      "Epoch 39/200\n",
      "3781/3781 [==============================] - 2s 453us/sample - loss: 0.2579 - accuracy: 0.8937 - val_loss: 1.0175 - val_accuracy: 0.6375\n",
      "Epoch 40/200\n",
      "3781/3781 [==============================] - 2s 498us/sample - loss: 0.2673 - accuracy: 0.8958 - val_loss: 0.9376 - val_accuracy: 0.6427\n",
      "Epoch 41/200\n",
      "3781/3781 [==============================] - 2s 527us/sample - loss: 0.2976 - accuracy: 0.8831 - val_loss: 1.0074 - val_accuracy: 0.6219\n",
      "Epoch 42/200\n",
      "3781/3781 [==============================] - 2s 498us/sample - loss: 0.2726 - accuracy: 0.8916 - val_loss: 0.9285 - val_accuracy: 0.6385\n",
      "Epoch 43/200\n",
      "3781/3781 [==============================] - 2s 468us/sample - loss: 0.2552 - accuracy: 0.8939 - val_loss: 1.0412 - val_accuracy: 0.6229\n",
      "Epoch 44/200\n",
      "3781/3781 [==============================] - 2s 505us/sample - loss: 0.2949 - accuracy: 0.8810 - val_loss: 1.0806 - val_accuracy: 0.5990\n",
      "Epoch 45/200\n",
      "3781/3781 [==============================] - 2s 518us/sample - loss: 0.2793 - accuracy: 0.8857 - val_loss: 0.8454 - val_accuracy: 0.6792\n",
      "Epoch 46/200\n",
      "3781/3781 [==============================] - 2s 527us/sample - loss: 0.2766 - accuracy: 0.8887 - val_loss: 0.8709 - val_accuracy: 0.7052\n",
      "Epoch 47/200\n",
      "3781/3781 [==============================] - 2s 462us/sample - loss: 0.2918 - accuracy: 0.8733 - val_loss: 0.9215 - val_accuracy: 0.6250\n",
      "Epoch 48/200\n",
      "3781/3781 [==============================] - 2s 488us/sample - loss: 0.3089 - accuracy: 0.8760 - val_loss: 1.0707 - val_accuracy: 0.6490\n",
      "Epoch 49/200\n",
      "3781/3781 [==============================] - 2s 499us/sample - loss: 0.2856 - accuracy: 0.8879 - val_loss: 1.0002 - val_accuracy: 0.6458\n",
      "Epoch 50/200\n",
      "3781/3781 [==============================] - 2s 471us/sample - loss: 0.2588 - accuracy: 0.8894 - val_loss: 1.0347 - val_accuracy: 0.6698\n",
      "Epoch 51/200\n",
      "3781/3781 [==============================] - 2s 517us/sample - loss: 0.2424 - accuracy: 0.8908 - val_loss: 1.0994 - val_accuracy: 0.6865\n",
      "Epoch 52/200\n",
      "3781/3781 [==============================] - 2s 482us/sample - loss: 0.2575 - accuracy: 0.8916 - val_loss: 1.0951 - val_accuracy: 0.6500\n",
      "Epoch 53/200\n",
      "3781/3781 [==============================] - 2s 465us/sample - loss: 0.2478 - accuracy: 0.8998 - val_loss: 1.2255 - val_accuracy: 0.6521\n",
      "Epoch 54/200\n",
      "3781/3781 [==============================] - 2s 509us/sample - loss: 0.2806 - accuracy: 0.8733 - val_loss: 1.3953 - val_accuracy: 0.6177\n",
      "Epoch 55/200\n",
      "3781/3781 [==============================] - 2s 444us/sample - loss: 0.2907 - accuracy: 0.8770 - val_loss: 0.9800 - val_accuracy: 0.6281\n",
      "Epoch 56/200\n",
      "3781/3781 [==============================] - 2s 461us/sample - loss: 0.2992 - accuracy: 0.8775 - val_loss: 1.0582 - val_accuracy: 0.6469\n",
      "Epoch 57/200\n",
      "3781/3781 [==============================] - 2s 460us/sample - loss: 0.2756 - accuracy: 0.8884 - val_loss: 1.5449 - val_accuracy: 0.6458\n",
      "Epoch 58/200\n",
      "3781/3781 [==============================] - 2s 479us/sample - loss: 0.2809 - accuracy: 0.8865 - val_loss: 1.0790 - val_accuracy: 0.6438\n",
      "Epoch 59/200\n",
      "3781/3781 [==============================] - 2s 492us/sample - loss: 0.2695 - accuracy: 0.8857 - val_loss: 1.2698 - val_accuracy: 0.6354\n",
      "Epoch 60/200\n",
      "3781/3781 [==============================] - 2s 472us/sample - loss: 0.3067 - accuracy: 0.8807 - val_loss: 0.9802 - val_accuracy: 0.6583\n",
      "Epoch 61/200\n",
      "3781/3781 [==============================] - 3s 716us/sample - loss: 0.2938 - accuracy: 0.8765 - val_loss: 1.0920 - val_accuracy: 0.6833\n",
      "Epoch 62/200\n",
      "3781/3781 [==============================] - 2s 558us/sample - loss: 0.2769 - accuracy: 0.8826 - val_loss: 1.3555 - val_accuracy: 0.6656\n",
      "Epoch 63/200\n",
      "3781/3781 [==============================] - 2s 492us/sample - loss: 0.2753 - accuracy: 0.8887 - val_loss: 1.1513 - val_accuracy: 0.6281\n",
      "Epoch 64/200\n",
      "3781/3781 [==============================] - 2s 523us/sample - loss: 0.2696 - accuracy: 0.8855 - val_loss: 1.0825 - val_accuracy: 0.6510\n",
      "Epoch 65/200\n",
      "3781/3781 [==============================] - 2s 413us/sample - loss: 0.2603 - accuracy: 0.8929 - val_loss: 1.2133 - val_accuracy: 0.6698\n",
      "Epoch 66/200\n",
      "3781/3781 [==============================] - 2s 498us/sample - loss: 0.2674 - accuracy: 0.8889 - val_loss: 1.1507 - val_accuracy: 0.6687\n",
      "Epoch 67/200\n",
      "3781/3781 [==============================] - 2s 624us/sample - loss: 0.2429 - accuracy: 0.8926 - val_loss: 1.5837 - val_accuracy: 0.6552\n",
      "Epoch 68/200\n",
      "3781/3781 [==============================] - 2s 562us/sample - loss: 0.2305 - accuracy: 0.8976 - val_loss: 1.5407 - val_accuracy: 0.6687\n",
      "Epoch 69/200\n",
      "3781/3781 [==============================] - 2s 636us/sample - loss: 0.2414 - accuracy: 0.9021 - val_loss: 1.3510 - val_accuracy: 0.6448\n",
      "Epoch 70/200\n",
      "3781/3781 [==============================] - 2s 618us/sample - loss: 0.2793 - accuracy: 0.8828 - val_loss: 1.4605 - val_accuracy: 0.6208\n",
      "Epoch 71/200\n",
      "3781/3781 [==============================] - 2s 570us/sample - loss: 0.2717 - accuracy: 0.8855 - val_loss: 1.3458 - val_accuracy: 0.6448\n",
      "Epoch 72/200\n",
      "3781/3781 [==============================] - 2s 590us/sample - loss: 0.2749 - accuracy: 0.8873 - val_loss: 1.5373 - val_accuracy: 0.6833\n",
      "Epoch 73/200\n",
      "3781/3781 [==============================] - 2s 652us/sample - loss: 0.2656 - accuracy: 0.8934 - val_loss: 1.2783 - val_accuracy: 0.7188\n",
      "Epoch 74/200\n",
      "3781/3781 [==============================] - 3s 744us/sample - loss: 0.2851 - accuracy: 0.8746 - val_loss: 1.1063 - val_accuracy: 0.6875\n",
      "Epoch 75/200\n",
      "3781/3781 [==============================] - 2s 559us/sample - loss: 0.2636 - accuracy: 0.8855 - val_loss: 1.3109 - val_accuracy: 0.6729\n",
      "Epoch 76/200\n",
      "3781/3781 [==============================] - 2s 557us/sample - loss: 0.2567 - accuracy: 0.8860 - val_loss: 1.1656 - val_accuracy: 0.7000\n",
      "Epoch 77/200\n",
      "3781/3781 [==============================] - 3s 668us/sample - loss: 0.2671 - accuracy: 0.8918 - val_loss: 1.0145 - val_accuracy: 0.6417\n",
      "Epoch 78/200\n",
      "3781/3781 [==============================] - 3s 722us/sample - loss: 0.2780 - accuracy: 0.8934 - val_loss: 1.0205 - val_accuracy: 0.7073\n",
      "Epoch 79/200\n",
      "3781/3781 [==============================] - 2s 517us/sample - loss: 0.2687 - accuracy: 0.8950 - val_loss: 1.2193 - val_accuracy: 0.6698\n",
      "Epoch 80/200\n",
      "3781/3781 [==============================] - 2s 473us/sample - loss: 0.2680 - accuracy: 0.8847 - val_loss: 1.4250 - val_accuracy: 0.6417\n",
      "Epoch 81/200\n",
      "3781/3781 [==============================] - 2s 491us/sample - loss: 0.2509 - accuracy: 0.8974 - val_loss: 1.6577 - val_accuracy: 0.6469\n",
      "Epoch 82/200\n",
      "3781/3781 [==============================] - 2s 519us/sample - loss: 0.2405 - accuracy: 0.9072 - val_loss: 1.5870 - val_accuracy: 0.6271\n",
      "Epoch 83/200\n",
      "3781/3781 [==============================] - 2s 506us/sample - loss: 0.2378 - accuracy: 0.9021 - val_loss: 1.2610 - val_accuracy: 0.6562\n",
      "Epoch 84/200\n",
      "3781/3781 [==============================] - 2s 481us/sample - loss: 0.2313 - accuracy: 0.9082 - val_loss: 1.2797 - val_accuracy: 0.6677\n",
      "Epoch 85/200\n",
      "3781/3781 [==============================] - 2s 502us/sample - loss: 0.2455 - accuracy: 0.8918 - val_loss: 2.4676 - val_accuracy: 0.6448\n",
      "Epoch 86/200\n",
      "3781/3781 [==============================] - 2s 454us/sample - loss: 0.2653 - accuracy: 0.8918 - val_loss: 1.6328 - val_accuracy: 0.6635\n",
      "Epoch 87/200\n",
      "3781/3781 [==============================] - 2s 488us/sample - loss: 0.2588 - accuracy: 0.8871 - val_loss: 1.7459 - val_accuracy: 0.6354\n",
      "Epoch 88/200\n",
      "3781/3781 [==============================] - 2s 416us/sample - loss: 0.2673 - accuracy: 0.8876 - val_loss: 1.5219 - val_accuracy: 0.6448\n",
      "Epoch 89/200\n",
      "3781/3781 [==============================] - 2s 492us/sample - loss: 0.2457 - accuracy: 0.8966 - val_loss: 2.0167 - val_accuracy: 0.6406\n",
      "Epoch 90/200\n",
      "3781/3781 [==============================] - 2s 487us/sample - loss: 0.2239 - accuracy: 0.9111 - val_loss: 2.3170 - val_accuracy: 0.6396\n",
      "Epoch 91/200\n",
      "3781/3781 [==============================] - 2s 504us/sample - loss: 0.2497 - accuracy: 0.8934 - val_loss: 1.3886 - val_accuracy: 0.6677\n",
      "Epoch 92/200\n",
      "3781/3781 [==============================] - 2s 438us/sample - loss: 0.2273 - accuracy: 0.9109 - val_loss: 2.3268 - val_accuracy: 0.6135\n",
      "Epoch 93/200\n",
      "3781/3781 [==============================] - 2s 456us/sample - loss: 0.2510 - accuracy: 0.9000 - val_loss: 1.7466 - val_accuracy: 0.6615\n",
      "Epoch 94/200\n",
      "3781/3781 [==============================] - 2s 495us/sample - loss: 0.2728 - accuracy: 0.8905 - val_loss: 1.6918 - val_accuracy: 0.6333\n",
      "Epoch 95/200\n",
      "3781/3781 [==============================] - 2s 497us/sample - loss: 0.2808 - accuracy: 0.8847 - val_loss: 2.2566 - val_accuracy: 0.6104\n",
      "Epoch 96/200\n",
      "3781/3781 [==============================] - 2s 515us/sample - loss: 0.2637 - accuracy: 0.8884 - val_loss: 2.1285 - val_accuracy: 0.6135\n",
      "Epoch 97/200\n",
      "3781/3781 [==============================] - 2s 621us/sample - loss: 0.2505 - accuracy: 0.8990 - val_loss: 1.9504 - val_accuracy: 0.6344\n",
      "Epoch 98/200\n",
      "3781/3781 [==============================] - 2s 640us/sample - loss: 0.2494 - accuracy: 0.8998 - val_loss: 1.3718 - val_accuracy: 0.7010\n",
      "Epoch 99/200\n",
      "3781/3781 [==============================] - 2s 564us/sample - loss: 0.2692 - accuracy: 0.8905 - val_loss: 1.9031 - val_accuracy: 0.6698\n",
      "Epoch 100/200\n",
      "3781/3781 [==============================] - 2s 587us/sample - loss: 0.2371 - accuracy: 0.9058 - val_loss: 2.2262 - val_accuracy: 0.6417\n",
      "Epoch 101/200\n",
      "3781/3781 [==============================] - 2s 567us/sample - loss: 0.2223 - accuracy: 0.9093 - val_loss: 1.7944 - val_accuracy: 0.6281\n",
      "Epoch 102/200\n",
      "3781/3781 [==============================] - 2s 534us/sample - loss: 0.2409 - accuracy: 0.9013 - val_loss: 2.9312 - val_accuracy: 0.5792\n",
      "Epoch 103/200\n",
      "3781/3781 [==============================] - 2s 535us/sample - loss: 0.2451 - accuracy: 0.8961 - val_loss: 2.7793 - val_accuracy: 0.5781\n",
      "Epoch 104/200\n",
      "3781/3781 [==============================] - 2s 570us/sample - loss: 0.2285 - accuracy: 0.9011 - val_loss: 2.4494 - val_accuracy: 0.6125\n",
      "Epoch 105/200\n",
      "3781/3781 [==============================] - 2s 582us/sample - loss: 0.2065 - accuracy: 0.9117 - val_loss: 2.1636 - val_accuracy: 0.6260\n",
      "Epoch 106/200\n",
      "3781/3781 [==============================] - 2s 539us/sample - loss: 0.2494 - accuracy: 0.8897 - val_loss: 1.2790 - val_accuracy: 0.6719\n",
      "Epoch 107/200\n",
      "3781/3781 [==============================] - 2s 549us/sample - loss: 0.2377 - accuracy: 0.8982 - val_loss: 1.8714 - val_accuracy: 0.6562\n",
      "Epoch 108/200\n",
      "3781/3781 [==============================] - 2s 550us/sample - loss: 0.2224 - accuracy: 0.9061 - val_loss: 1.2192 - val_accuracy: 0.6646\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3781/3781 [==============================] - 2s 494us/sample - loss: 0.2373 - accuracy: 0.8963 - val_loss: 1.3403 - val_accuracy: 0.6448\n",
      "Epoch 110/200\n",
      "3781/3781 [==============================] - 2s 473us/sample - loss: 0.2151 - accuracy: 0.9111 - val_loss: 2.2891 - val_accuracy: 0.6125\n",
      "Epoch 111/200\n",
      "3781/3781 [==============================] - 2s 456us/sample - loss: 0.2416 - accuracy: 0.9061 - val_loss: 1.9382 - val_accuracy: 0.6177\n",
      "Epoch 112/200\n",
      "3781/3781 [==============================] - 2s 483us/sample - loss: 0.2122 - accuracy: 0.9148 - val_loss: 2.2452 - val_accuracy: 0.6167\n",
      "Epoch 113/200\n",
      "3781/3781 [==============================] - 2s 474us/sample - loss: 0.2229 - accuracy: 0.9093 - val_loss: 4.1282 - val_accuracy: 0.5885\n",
      "Epoch 114/200\n",
      "3781/3781 [==============================] - 2s 459us/sample - loss: 0.2146 - accuracy: 0.9095 - val_loss: 3.2526 - val_accuracy: 0.5906\n",
      "Epoch 115/200\n",
      "3781/3781 [==============================] - 2s 489us/sample - loss: 0.2093 - accuracy: 0.9125 - val_loss: 2.3024 - val_accuracy: 0.6344\n",
      "Epoch 116/200\n",
      "3781/3781 [==============================] - 2s 511us/sample - loss: 0.2012 - accuracy: 0.9188 - val_loss: 3.2992 - val_accuracy: 0.5948\n",
      "Epoch 117/200\n",
      "3781/3781 [==============================] - 2s 490us/sample - loss: 0.2294 - accuracy: 0.9101 - val_loss: 1.9847 - val_accuracy: 0.6177\n",
      "Epoch 118/200\n",
      "3781/3781 [==============================] - 2s 543us/sample - loss: 0.2346 - accuracy: 0.9006 - val_loss: 1.6736 - val_accuracy: 0.6385\n",
      "Epoch 119/200\n",
      "3781/3781 [==============================] - 2s 444us/sample - loss: 0.2167 - accuracy: 0.9122 - val_loss: 2.5498 - val_accuracy: 0.6031\n",
      "Epoch 120/200\n",
      "3781/3781 [==============================] - 2s 449us/sample - loss: 0.2330 - accuracy: 0.9016 - val_loss: 2.8253 - val_accuracy: 0.6167\n",
      "Epoch 121/200\n",
      "3781/3781 [==============================] - 2s 469us/sample - loss: 0.2578 - accuracy: 0.8879 - val_loss: 1.0776 - val_accuracy: 0.6583\n",
      "Epoch 122/200\n",
      "3781/3781 [==============================] - 2s 504us/sample - loss: 0.2568 - accuracy: 0.8802 - val_loss: 0.9975 - val_accuracy: 0.6875\n",
      "Epoch 123/200\n",
      "3781/3781 [==============================] - 2s 526us/sample - loss: 0.2625 - accuracy: 0.8775 - val_loss: 1.5643 - val_accuracy: 0.6167\n",
      "Epoch 124/200\n",
      "3781/3781 [==============================] - 2s 487us/sample - loss: 0.2417 - accuracy: 0.8982 - val_loss: 2.3138 - val_accuracy: 0.6042\n",
      "Epoch 125/200\n",
      "3781/3781 [==============================] - 2s 496us/sample - loss: 0.2472 - accuracy: 0.8953 - val_loss: 1.3253 - val_accuracy: 0.6354\n",
      "Epoch 126/200\n",
      "3781/3781 [==============================] - 2s 481us/sample - loss: 0.2230 - accuracy: 0.9003 - val_loss: 1.6977 - val_accuracy: 0.6073\n",
      "Epoch 127/200\n",
      "3781/3781 [==============================] - 2s 498us/sample - loss: 0.1994 - accuracy: 0.9109 - val_loss: 1.6267 - val_accuracy: 0.6094\n",
      "Epoch 128/200\n",
      "3781/3781 [==============================] - 2s 502us/sample - loss: 0.2292 - accuracy: 0.9032 - val_loss: 1.6594 - val_accuracy: 0.6052\n",
      "Epoch 129/200\n",
      "3781/3781 [==============================] - 2s 496us/sample - loss: 0.2187 - accuracy: 0.9006 - val_loss: 1.5771 - val_accuracy: 0.6562\n",
      "Epoch 130/200\n",
      "3781/3781 [==============================] - 2s 508us/sample - loss: 0.2313 - accuracy: 0.8934 - val_loss: 2.0051 - val_accuracy: 0.6292\n",
      "Epoch 131/200\n",
      "3781/3781 [==============================] - 2s 537us/sample - loss: 0.2469 - accuracy: 0.8847 - val_loss: 1.8288 - val_accuracy: 0.5865\n",
      "Epoch 132/200\n",
      "3781/3781 [==============================] - 2s 486us/sample - loss: 0.2460 - accuracy: 0.8908 - val_loss: 2.3425 - val_accuracy: 0.6000\n",
      "Epoch 133/200\n",
      "3781/3781 [==============================] - 2s 528us/sample - loss: 0.2511 - accuracy: 0.8791 - val_loss: 1.4677 - val_accuracy: 0.6021\n",
      "Epoch 134/200\n",
      "3781/3781 [==============================] - 2s 519us/sample - loss: 0.2765 - accuracy: 0.8828 - val_loss: 1.5213 - val_accuracy: 0.6104\n",
      "Epoch 135/200\n",
      "3781/3781 [==============================] - 2s 511us/sample - loss: 0.2422 - accuracy: 0.8984 - val_loss: 2.7162 - val_accuracy: 0.5969\n",
      "Epoch 136/200\n",
      "3781/3781 [==============================] - 2s 482us/sample - loss: 0.2219 - accuracy: 0.9098 - val_loss: 2.5552 - val_accuracy: 0.5781\n",
      "Epoch 137/200\n",
      "3781/3781 [==============================] - 2s 475us/sample - loss: 0.2484 - accuracy: 0.8969 - val_loss: 1.3354 - val_accuracy: 0.6406\n",
      "Epoch 138/200\n",
      "3781/3781 [==============================] - 2s 497us/sample - loss: 0.2216 - accuracy: 0.9032 - val_loss: 1.2988 - val_accuracy: 0.6729\n",
      "Epoch 139/200\n",
      "3781/3781 [==============================] - 2s 489us/sample - loss: 0.2240 - accuracy: 0.9061 - val_loss: 1.7563 - val_accuracy: 0.6094\n",
      "Epoch 140/200\n",
      "3781/3781 [==============================] - 2s 487us/sample - loss: 0.2210 - accuracy: 0.9125 - val_loss: 1.7922 - val_accuracy: 0.6427\n",
      "Epoch 141/200\n",
      "3781/3781 [==============================] - 2s 473us/sample - loss: 0.2175 - accuracy: 0.9106 - val_loss: 2.4091 - val_accuracy: 0.6146\n",
      "Epoch 142/200\n",
      "3781/3781 [==============================] - 2s 487us/sample - loss: 0.1936 - accuracy: 0.9236 - val_loss: 3.5188 - val_accuracy: 0.6104\n",
      "Epoch 143/200\n",
      "3781/3781 [==============================] - 2s 469us/sample - loss: 0.2283 - accuracy: 0.9111 - val_loss: 2.1454 - val_accuracy: 0.5990\n",
      "Epoch 144/200\n",
      "3781/3781 [==============================] - 2s 453us/sample - loss: 0.2124 - accuracy: 0.9154 - val_loss: 1.9245 - val_accuracy: 0.6333\n",
      "Epoch 145/200\n",
      "3781/3781 [==============================] - 2s 508us/sample - loss: 0.2153 - accuracy: 0.9098 - val_loss: 2.1666 - val_accuracy: 0.6292\n",
      "Epoch 146/200\n",
      "3781/3781 [==============================] - 2s 513us/sample - loss: 0.2355 - accuracy: 0.8998 - val_loss: 1.9016 - val_accuracy: 0.6344\n",
      "Epoch 147/200\n",
      "3781/3781 [==============================] - 2s 511us/sample - loss: 0.2161 - accuracy: 0.9061 - val_loss: 2.0607 - val_accuracy: 0.6365\n",
      "Epoch 148/200\n",
      "3781/3781 [==============================] - 3s 664us/sample - loss: 0.2175 - accuracy: 0.9069 - val_loss: 2.2213 - val_accuracy: 0.6313\n",
      "Epoch 149/200\n",
      "3781/3781 [==============================] - 2s 540us/sample - loss: 0.2374 - accuracy: 0.8931 - val_loss: 1.4878 - val_accuracy: 0.6292\n",
      "Epoch 150/200\n",
      "3781/3781 [==============================] - 2s 565us/sample - loss: 0.2085 - accuracy: 0.9045 - val_loss: 1.9296 - val_accuracy: 0.6250\n",
      "Epoch 151/200\n",
      "3781/3781 [==============================] - 2s 486us/sample - loss: 0.1974 - accuracy: 0.9106 - val_loss: 2.8091 - val_accuracy: 0.5969\n",
      "Epoch 152/200\n",
      "3781/3781 [==============================] - 2s 593us/sample - loss: 0.2328 - accuracy: 0.8961 - val_loss: 2.4806 - val_accuracy: 0.6052\n",
      "Epoch 153/200\n",
      "3781/3781 [==============================] - 2s 529us/sample - loss: 0.2146 - accuracy: 0.9029 - val_loss: 2.4839 - val_accuracy: 0.5833\n",
      "Epoch 154/200\n",
      "3781/3781 [==============================] - 3s 663us/sample - loss: 0.2287 - accuracy: 0.9000 - val_loss: 1.1071 - val_accuracy: 0.6469\n",
      "Epoch 155/200\n",
      "3781/3781 [==============================] - 2s 644us/sample - loss: 0.2210 - accuracy: 0.9032 - val_loss: 2.4122 - val_accuracy: 0.5844\n",
      "Epoch 156/200\n",
      "3781/3781 [==============================] - 2s 563us/sample - loss: 0.1962 - accuracy: 0.9199 - val_loss: 2.1667 - val_accuracy: 0.5990\n",
      "Epoch 157/200\n",
      "3781/3781 [==============================] - 2s 529us/sample - loss: 0.2118 - accuracy: 0.9122 - val_loss: 1.6908 - val_accuracy: 0.6115\n",
      "Epoch 158/200\n",
      "3781/3781 [==============================] - 2s 561us/sample - loss: 0.1799 - accuracy: 0.9191 - val_loss: 2.8193 - val_accuracy: 0.6073\n",
      "Epoch 159/200\n",
      "3781/3781 [==============================] - 2s 571us/sample - loss: 0.1737 - accuracy: 0.9225 - val_loss: 2.4838 - val_accuracy: 0.6250\n",
      "Epoch 160/200\n",
      "3781/3781 [==============================] - 2s 558us/sample - loss: 0.2037 - accuracy: 0.9098 - val_loss: 1.8465 - val_accuracy: 0.6438\n",
      "Epoch 161/200\n",
      "3781/3781 [==============================] - 2s 553us/sample - loss: 0.2221 - accuracy: 0.9027 - val_loss: 1.5886 - val_accuracy: 0.6458\n",
      "Epoch 162/200\n",
      "3781/3781 [==============================] - 2s 528us/sample - loss: 0.2227 - accuracy: 0.9069 - val_loss: 1.9006 - val_accuracy: 0.6333\n",
      "Epoch 163/200\n",
      "3781/3781 [==============================] - 2s 450us/sample - loss: 0.2051 - accuracy: 0.9138 - val_loss: 2.2610 - val_accuracy: 0.6042\n",
      "Epoch 164/200\n",
      "3781/3781 [==============================] - 2s 489us/sample - loss: 0.2144 - accuracy: 0.9156 - val_loss: 2.7504 - val_accuracy: 0.5969\n",
      "Epoch 165/200\n",
      "3781/3781 [==============================] - 2s 487us/sample - loss: 0.1932 - accuracy: 0.9188 - val_loss: 2.4637 - val_accuracy: 0.6177\n",
      "Epoch 166/200\n",
      "3781/3781 [==============================] - 2s 498us/sample - loss: 0.2086 - accuracy: 0.9114 - val_loss: 3.7280 - val_accuracy: 0.5833\n",
      "Epoch 167/200\n",
      "3781/3781 [==============================] - 2s 499us/sample - loss: 0.1955 - accuracy: 0.9164 - val_loss: 2.4132 - val_accuracy: 0.6010\n",
      "Epoch 168/200\n",
      "3781/3781 [==============================] - 2s 503us/sample - loss: 0.1759 - accuracy: 0.9289 - val_loss: 2.3405 - val_accuracy: 0.6031\n",
      "Epoch 169/200\n",
      "3781/3781 [==============================] - 2s 521us/sample - loss: 0.1669 - accuracy: 0.9312 - val_loss: 3.8447 - val_accuracy: 0.5792\n",
      "Epoch 170/200\n",
      "3781/3781 [==============================] - 2s 514us/sample - loss: 0.1783 - accuracy: 0.9249 - val_loss: 3.8207 - val_accuracy: 0.5938\n",
      "Epoch 171/200\n",
      "3781/3781 [==============================] - 2s 483us/sample - loss: 0.1836 - accuracy: 0.9299 - val_loss: 3.0505 - val_accuracy: 0.6094\n",
      "Epoch 172/200\n",
      "3781/3781 [==============================] - 2s 493us/sample - loss: 0.1691 - accuracy: 0.9344 - val_loss: 4.4399 - val_accuracy: 0.5979\n",
      "Epoch 173/200\n",
      "3781/3781 [==============================] - 2s 484us/sample - loss: 0.2376 - accuracy: 0.9064 - val_loss: 1.6616 - val_accuracy: 0.6073\n",
      "Epoch 174/200\n",
      "3781/3781 [==============================] - 2s 487us/sample - loss: 0.1953 - accuracy: 0.9222 - val_loss: 3.3276 - val_accuracy: 0.5958\n",
      "Epoch 175/200\n",
      "3781/3781 [==============================] - 2s 487us/sample - loss: 0.1958 - accuracy: 0.9188 - val_loss: 3.7541 - val_accuracy: 0.5604\n",
      "Epoch 176/200\n",
      "3781/3781 [==============================] - 2s 486us/sample - loss: 0.2163 - accuracy: 0.9077 - val_loss: 2.3793 - val_accuracy: 0.5938\n",
      "Epoch 177/200\n",
      "3781/3781 [==============================] - 2s 475us/sample - loss: 0.1857 - accuracy: 0.9204 - val_loss: 2.1482 - val_accuracy: 0.6344\n",
      "Epoch 178/200\n",
      "3781/3781 [==============================] - 2s 527us/sample - loss: 0.1910 - accuracy: 0.9212 - val_loss: 2.8160 - val_accuracy: 0.6052\n",
      "Epoch 179/200\n",
      "3781/3781 [==============================] - 2s 459us/sample - loss: 0.1926 - accuracy: 0.9180 - val_loss: 3.9230 - val_accuracy: 0.6042\n",
      "Epoch 180/200\n",
      "3781/3781 [==============================] - 2s 507us/sample - loss: 0.1691 - accuracy: 0.9252 - val_loss: 1.9341 - val_accuracy: 0.6375\n",
      "Epoch 181/200\n",
      "3781/3781 [==============================] - 2s 506us/sample - loss: 0.1812 - accuracy: 0.9172 - val_loss: 1.9088 - val_accuracy: 0.6281\n",
      "Epoch 182/200\n",
      "3781/3781 [==============================] - 2s 531us/sample - loss: 0.1834 - accuracy: 0.9183 - val_loss: 2.1289 - val_accuracy: 0.6271\n",
      "Epoch 183/200\n",
      "3781/3781 [==============================] - 2s 548us/sample - loss: 0.1809 - accuracy: 0.9241 - val_loss: 1.6706 - val_accuracy: 0.6198\n",
      "Epoch 184/200\n",
      "3781/3781 [==============================] - 2s 566us/sample - loss: 0.1812 - accuracy: 0.9175 - val_loss: 1.6838 - val_accuracy: 0.6562\n",
      "Epoch 185/200\n",
      "3781/3781 [==============================] - 2s 537us/sample - loss: 0.1733 - accuracy: 0.9238 - val_loss: 1.8135 - val_accuracy: 0.6125\n",
      "Epoch 186/200\n",
      "3781/3781 [==============================] - 2s 478us/sample - loss: 0.1942 - accuracy: 0.9111 - val_loss: 1.4726 - val_accuracy: 0.6500\n",
      "Epoch 187/200\n",
      "3781/3781 [==============================] - 2s 522us/sample - loss: 0.1762 - accuracy: 0.9162 - val_loss: 1.6512 - val_accuracy: 0.6344\n",
      "Epoch 188/200\n",
      "3781/3781 [==============================] - 2s 507us/sample - loss: 0.2006 - accuracy: 0.9074 - val_loss: 1.2571 - val_accuracy: 0.6583\n",
      "Epoch 189/200\n",
      "3781/3781 [==============================] - 2s 487us/sample - loss: 0.1880 - accuracy: 0.9154 - val_loss: 1.5661 - val_accuracy: 0.6448\n",
      "Epoch 190/200\n",
      "3781/3781 [==============================] - 2s 461us/sample - loss: 0.1961 - accuracy: 0.9109 - val_loss: 1.4620 - val_accuracy: 0.6385\n",
      "Epoch 191/200\n",
      "3781/3781 [==============================] - 2s 517us/sample - loss: 0.1850 - accuracy: 0.9088 - val_loss: 1.5017 - val_accuracy: 0.6552\n",
      "Epoch 192/200\n",
      "3781/3781 [==============================] - 2s 536us/sample - loss: 0.1879 - accuracy: 0.9154 - val_loss: 1.3774 - val_accuracy: 0.6469\n",
      "Epoch 193/200\n",
      "3781/3781 [==============================] - 2s 513us/sample - loss: 0.1789 - accuracy: 0.9175 - val_loss: 1.5202 - val_accuracy: 0.6500\n",
      "Epoch 194/200\n",
      "3781/3781 [==============================] - 2s 570us/sample - loss: 0.1832 - accuracy: 0.9140 - val_loss: 1.4946 - val_accuracy: 0.6521\n",
      "Epoch 195/200\n",
      "3781/3781 [==============================] - 2s 505us/sample - loss: 0.1848 - accuracy: 0.9103 - val_loss: 1.7912 - val_accuracy: 0.6260\n",
      "Epoch 196/200\n",
      "3781/3781 [==============================] - 2s 505us/sample - loss: 0.1826 - accuracy: 0.9114 - val_loss: 1.3895 - val_accuracy: 0.6687\n",
      "Epoch 197/200\n",
      "3781/3781 [==============================] - 2s 534us/sample - loss: 0.1904 - accuracy: 0.9117 - val_loss: 1.2948 - val_accuracy: 0.6552\n",
      "Epoch 198/200\n",
      "3781/3781 [==============================] - 2s 492us/sample - loss: 0.1943 - accuracy: 0.9035 - val_loss: 1.6007 - val_accuracy: 0.6708\n",
      "Epoch 199/200\n",
      "3781/3781 [==============================] - 2s 506us/sample - loss: 0.1713 - accuracy: 0.9217 - val_loss: 2.1634 - val_accuracy: 0.6552\n",
      "Epoch 200/200\n",
      "3781/3781 [==============================] - 2s 558us/sample - loss: 0.1459 - accuracy: 0.9371 - val_loss: 2.4779 - val_accuracy: 0.6219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3942b9d8d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(activation1='relu',activation2='softmax',\n",
    "             d=0.5,n1=1024,n2=1512,n3=1512,n4=1024,n5=768,n6=256,n7=3)\n",
    "\n",
    "# Compile model\n",
    "    \n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='Adam', metrics=['accuracy'])\n",
    "#               weighted_metrics=['accuracy'])\n",
    "earlier = EarlyStopping(monitor = 'val_accuracy',mode='max',min_delta=1e-3,patience=50,verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath='best.hdf5',verbose=1, save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=200, batch_size=150\n",
    "          , validation_data=(X_val, Y_val,val_sample_weights)\n",
    "#           , callbacks=[earlier, checkpointer])\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_model_weights_crossentropy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# model.load_weights('best.hdf5')\n",
    "Y_test = model.predict_classes(X_test)\n",
    "print(Y_test)\n",
    "\n",
    "\n",
    "f = open(\"best_cre_0.csv\", \"w\")\n",
    "f.write(\"id,y\\n\")\n",
    "for i,x in enumerate(Y_test):\n",
    "    f.write(\"{},{}\\n\".format(i,x))\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3781 samples, validate on 960 samples\n",
      "Epoch 1/200\n",
      "3781/3781 [==============================] - 3s 702us/sample - loss: 0.2471 - accuracy: 0.6652 - accuracy_1: 0.6652 - val_loss: 0.1344 - val_accuracy: 0.5885 - val_accuracy_1: 0.5208\n",
      "Epoch 2/200\n",
      "3781/3781 [==============================] - 2s 499us/sample - loss: 0.1324 - accuracy: 0.7487 - accuracy_1: 0.7487 - val_loss: 0.1345 - val_accuracy: 0.6031 - val_accuracy_1: 0.5644\n",
      "Epoch 3/200\n",
      "3781/3781 [==============================] - 2s 550us/sample - loss: 0.1309 - accuracy: 0.8072 - accuracy_1: 0.8072 - val_loss: 0.1336 - val_accuracy: 0.5979 - val_accuracy_1: 0.6222\n",
      "Epoch 4/200\n",
      "3781/3781 [==============================] - 2s 509us/sample - loss: 0.1297 - accuracy: 0.8183 - accuracy_1: 0.8183 - val_loss: 0.1340 - val_accuracy: 0.5885 - val_accuracy_1: 0.6296\n",
      "Epoch 5/200\n",
      "3781/3781 [==============================] - 2s 511us/sample - loss: 0.1291 - accuracy: 0.8270 - accuracy_1: 0.8270 - val_loss: 0.1353 - val_accuracy: 0.5677 - val_accuracy_1: 0.6088\n",
      "Epoch 6/200\n",
      "3781/3781 [==============================] - 2s 545us/sample - loss: 0.1286 - accuracy: 0.8310 - accuracy_1: 0.8310 - val_loss: 0.1362 - val_accuracy: 0.5552 - val_accuracy_1: 0.5708\n",
      "Epoch 7/200\n",
      "3781/3781 [==============================] - 2s 570us/sample - loss: 0.1285 - accuracy: 0.8368 - accuracy_1: 0.8368 - val_loss: 0.1368 - val_accuracy: 0.5792 - val_accuracy_1: 0.6093\n",
      "Epoch 8/200\n",
      "3781/3781 [==============================] - 2s 513us/sample - loss: 0.1278 - accuracy: 0.8641 - accuracy_1: 0.8641 - val_loss: 0.1355 - val_accuracy: 0.5688 - val_accuracy_1: 0.5977\n",
      "Epoch 9/200\n",
      "3781/3781 [==============================] - 2s 524us/sample - loss: 0.1275 - accuracy: 0.8725 - accuracy_1: 0.8725 - val_loss: 0.1358 - val_accuracy: 0.5458 - val_accuracy_1: 0.5690\n",
      "Epoch 10/200\n",
      "3781/3781 [==============================] - 2s 546us/sample - loss: 0.1270 - accuracy: 0.8794 - accuracy_1: 0.8794 - val_loss: 0.1391 - val_accuracy: 0.5583 - val_accuracy_1: 0.5769\n",
      "Epoch 11/200\n",
      "3781/3781 [==============================] - 2s 520us/sample - loss: 0.1271 - accuracy: 0.8638 - accuracy_1: 0.8638 - val_loss: 0.1398 - val_accuracy: 0.5385 - val_accuracy_1: 0.5588\n",
      "Epoch 12/200\n",
      "3781/3781 [==============================] - 2s 492us/sample - loss: 0.1275 - accuracy: 0.8701 - accuracy_1: 0.8701 - val_loss: 0.1373 - val_accuracy: 0.5583 - val_accuracy_1: 0.6023\n",
      "Epoch 13/200\n",
      "3781/3781 [==============================] - 2s 486us/sample - loss: 0.1272 - accuracy: 0.8638 - accuracy_1: 0.8638 - val_loss: 0.1389 - val_accuracy: 0.5698 - val_accuracy_1: 0.5611\n",
      "Epoch 14/200\n",
      "3781/3781 [==============================] - 2s 531us/sample - loss: 0.1273 - accuracy: 0.8604 - accuracy_1: 0.8604 - val_loss: 0.1428 - val_accuracy: 0.5510 - val_accuracy_1: 0.5620\n",
      "Epoch 15/200\n",
      "3781/3781 [==============================] - 2s 529us/sample - loss: 0.1277 - accuracy: 0.8683 - accuracy_1: 0.8683 - val_loss: 0.1394 - val_accuracy: 0.5365 - val_accuracy_1: 0.5694\n",
      "Epoch 16/200\n",
      "3781/3781 [==============================] - 2s 542us/sample - loss: 0.1271 - accuracy: 0.8556 - accuracy_1: 0.8556 - val_loss: 0.1368 - val_accuracy: 0.5792 - val_accuracy_1: 0.6417\n",
      "Epoch 17/200\n",
      "3781/3781 [==============================] - 2s 550us/sample - loss: 0.1270 - accuracy: 0.8778 - accuracy_1: 0.8778 - val_loss: 0.1395 - val_accuracy: 0.5448 - val_accuracy_1: 0.5685\n",
      "Epoch 18/200\n",
      "3781/3781 [==============================] - 2s 578us/sample - loss: 0.1266 - accuracy: 0.8810 - accuracy_1: 0.8810 - val_loss: 0.1394 - val_accuracy: 0.5594 - val_accuracy_1: 0.5912\n",
      "Epoch 19/200\n",
      "3781/3781 [==============================] - 2s 511us/sample - loss: 0.1268 - accuracy: 0.8823 - accuracy_1: 0.8823 - val_loss: 0.1406 - val_accuracy: 0.5344 - val_accuracy_1: 0.5778\n",
      "Epoch 20/200\n",
      "3781/3781 [==============================] - 2s 491us/sample - loss: 0.1262 - accuracy: 0.8937 - accuracy_1: 0.8937 - val_loss: 0.1383 - val_accuracy: 0.5740 - val_accuracy_1: 0.6139\n",
      "Epoch 21/200\n",
      "3781/3781 [==============================] - 2s 506us/sample - loss: 0.1269 - accuracy: 0.8699 - accuracy_1: 0.8699 - val_loss: 0.1426 - val_accuracy: 0.5167 - val_accuracy_1: 0.5699\n",
      "Epoch 22/200\n",
      "3781/3781 [==============================] - 2s 552us/sample - loss: 0.1265 - accuracy: 0.8850 - accuracy_1: 0.8850 - val_loss: 0.1412 - val_accuracy: 0.5458 - val_accuracy_1: 0.5782\n",
      "Epoch 23/200\n",
      "3781/3781 [==============================] - 2s 544us/sample - loss: 0.1261 - accuracy: 0.8873 - accuracy_1: 0.8873 - val_loss: 0.1409 - val_accuracy: 0.5729 - val_accuracy_1: 0.5833\n",
      "Epoch 24/200\n",
      "3781/3781 [==============================] - 2s 487us/sample - loss: 0.1261 - accuracy: 0.9035 - accuracy_1: 0.9035 - val_loss: 0.1417 - val_accuracy: 0.5667 - val_accuracy_1: 0.5829\n",
      "Epoch 25/200\n",
      "3781/3781 [==============================] - 2s 528us/sample - loss: 0.1262 - accuracy: 0.8969 - accuracy_1: 0.8969 - val_loss: 0.1434 - val_accuracy: 0.5448 - val_accuracy_1: 0.5662\n",
      "Epoch 26/200\n",
      "3781/3781 [==============================] - 2s 495us/sample - loss: 0.1263 - accuracy: 0.8934 - accuracy_1: 0.8934 - val_loss: 0.1422 - val_accuracy: 0.5625 - val_accuracy_1: 0.5833\n",
      "Epoch 27/200\n",
      "3781/3781 [==============================] - 2s 547us/sample - loss: 0.1260 - accuracy: 0.8990 - accuracy_1: 0.8990 - val_loss: 0.1414 - val_accuracy: 0.5552 - val_accuracy_1: 0.5778\n",
      "Epoch 28/200\n",
      "3781/3781 [==============================] - 2s 482us/sample - loss: 0.1258 - accuracy: 0.9006 - accuracy_1: 0.9006 - val_loss: 0.1409 - val_accuracy: 0.5396 - val_accuracy_1: 0.5847\n",
      "Epoch 29/200\n",
      "3781/3781 [==============================] - 2s 498us/sample - loss: 0.1259 - accuracy: 0.9027 - accuracy_1: 0.9027 - val_loss: 0.1423 - val_accuracy: 0.5354 - val_accuracy_1: 0.5667\n",
      "Epoch 30/200\n",
      "3781/3781 [==============================] - 2s 482us/sample - loss: 0.1259 - accuracy: 0.9106 - accuracy_1: 0.9106 - val_loss: 0.1419 - val_accuracy: 0.5271 - val_accuracy_1: 0.5745\n",
      "Epoch 31/200\n",
      "3781/3781 [==============================] - 2s 524us/sample - loss: 0.1260 - accuracy: 0.9072 - accuracy_1: 0.9072 - val_loss: 0.1420 - val_accuracy: 0.5458 - val_accuracy_1: 0.5620\n",
      "Epoch 32/200\n",
      "3781/3781 [==============================] - 2s 485us/sample - loss: 0.1261 - accuracy: 0.9082 - accuracy_1: 0.9082 - val_loss: 0.1390 - val_accuracy: 0.5437 - val_accuracy_1: 0.6005\n",
      "Epoch 33/200\n",
      "3781/3781 [==============================] - 2s 554us/sample - loss: 0.1266 - accuracy: 0.8900 - accuracy_1: 0.8900 - val_loss: 0.1411 - val_accuracy: 0.5312 - val_accuracy_1: 0.5579\n",
      "Epoch 34/200\n",
      "3781/3781 [==============================] - 2s 592us/sample - loss: 0.1273 - accuracy: 0.8551 - accuracy_1: 0.8551 - val_loss: 0.1383 - val_accuracy: 0.5510 - val_accuracy_1: 0.5597\n",
      "Epoch 35/200\n",
      "3781/3781 [==============================] - 2s 529us/sample - loss: 0.1268 - accuracy: 0.8609 - accuracy_1: 0.8609 - val_loss: 0.1435 - val_accuracy: 0.5333 - val_accuracy_1: 0.5634\n",
      "Epoch 36/200\n",
      "3781/3781 [==============================] - 2s 474us/sample - loss: 0.1272 - accuracy: 0.8511 - accuracy_1: 0.8511 - val_loss: 0.1383 - val_accuracy: 0.5813 - val_accuracy_1: 0.6310\n",
      "Epoch 37/200\n",
      "3781/3781 [==============================] - 2s 486us/sample - loss: 0.1266 - accuracy: 0.8659 - accuracy_1: 0.8659 - val_loss: 0.1424 - val_accuracy: 0.5625 - val_accuracy_1: 0.5741\n",
      "Epoch 38/200\n",
      "3781/3781 [==============================] - 2s 536us/sample - loss: 0.1263 - accuracy: 0.8850 - accuracy_1: 0.8850 - val_loss: 0.1419 - val_accuracy: 0.5448 - val_accuracy_1: 0.5685\n",
      "Epoch 39/200\n",
      "3781/3781 [==============================] - 2s 492us/sample - loss: 0.1263 - accuracy: 0.8725 - accuracy_1: 0.8725 - val_loss: 0.1411 - val_accuracy: 0.5552 - val_accuracy_1: 0.5870\n",
      "Epoch 40/200\n",
      "3781/3781 [==============================] - 2s 562us/sample - loss: 0.1262 - accuracy: 0.8812 - accuracy_1: 0.8812 - val_loss: 0.1394 - val_accuracy: 0.5885 - val_accuracy_1: 0.5903\n",
      "Epoch 41/200\n",
      "3781/3781 [==============================] - 2s 539us/sample - loss: 0.1260 - accuracy: 0.8990 - accuracy_1: 0.8990 - val_loss: 0.1418 - val_accuracy: 0.5760 - val_accuracy_1: 0.5870\n",
      "Epoch 42/200\n",
      "3781/3781 [==============================] - 2s 558us/sample - loss: 0.1264 - accuracy: 0.8950 - accuracy_1: 0.8950 - val_loss: 0.1415 - val_accuracy: 0.5385 - val_accuracy_1: 0.5657\n",
      "Epoch 43/200\n",
      "3781/3781 [==============================] - 2s 593us/sample - loss: 0.1267 - accuracy: 0.8744 - accuracy_1: 0.8744 - val_loss: 0.1405 - val_accuracy: 0.5417 - val_accuracy_1: 0.5625\n",
      "Epoch 44/200\n",
      "3781/3781 [==============================] - 2s 603us/sample - loss: 0.1273 - accuracy: 0.8654 - accuracy_1: 0.8654 - val_loss: 0.1420 - val_accuracy: 0.5583 - val_accuracy_1: 0.5745\n",
      "Epoch 45/200\n",
      "3781/3781 [==============================] - 2s 515us/sample - loss: 0.1268 - accuracy: 0.8717 - accuracy_1: 0.8717 - val_loss: 0.1435 - val_accuracy: 0.5479 - val_accuracy_1: 0.5606\n",
      "Epoch 46/200\n",
      "3781/3781 [==============================] - 3s 752us/sample - loss: 0.1275 - accuracy: 0.8540 - accuracy_1: 0.8540 - val_loss: 0.1365 - val_accuracy: 0.5667 - val_accuracy_1: 0.6593\n",
      "Epoch 47/200\n",
      "3781/3781 [==============================] - 2s 576us/sample - loss: 0.1281 - accuracy: 0.8331 - accuracy_1: 0.8331 - val_loss: 0.1361 - val_accuracy: 0.6094 - val_accuracy_1: 0.6435\n",
      "Epoch 48/200\n",
      "3781/3781 [==============================] - 2s 525us/sample - loss: 0.1278 - accuracy: 0.8408 - accuracy_1: 0.8408 - val_loss: 0.1403 - val_accuracy: 0.5708 - val_accuracy_1: 0.6056\n",
      "Epoch 49/200\n",
      "3781/3781 [==============================] - 2s 630us/sample - loss: 0.1284 - accuracy: 0.8059 - accuracy_1: 0.8059 - val_loss: 0.1393 - val_accuracy: 0.5677 - val_accuracy_1: 0.5903\n",
      "Epoch 50/200\n",
      "3781/3781 [==============================] - 2s 595us/sample - loss: 0.1272 - accuracy: 0.8567 - accuracy_1: 0.8567 - val_loss: 0.1346 - val_accuracy: 0.6135 - val_accuracy_1: 0.6708\n",
      "Epoch 51/200\n",
      "3781/3781 [==============================] - 2s 543us/sample - loss: 0.1274 - accuracy: 0.8651 - accuracy_1: 0.8651 - val_loss: 0.1396 - val_accuracy: 0.5562 - val_accuracy_1: 0.5713\n",
      "Epoch 52/200\n",
      "3781/3781 [==============================] - 2s 562us/sample - loss: 0.1272 - accuracy: 0.8596 - accuracy_1: 0.8596 - val_loss: 0.1433 - val_accuracy: 0.5667 - val_accuracy_1: 0.5620\n",
      "Epoch 53/200\n",
      "3781/3781 [==============================] - 2s 581us/sample - loss: 0.1270 - accuracy: 0.8683 - accuracy_1: 0.8683 - val_loss: 0.1420 - val_accuracy: 0.5938 - val_accuracy_1: 0.5880\n",
      "Epoch 54/200\n",
      "3781/3781 [==============================] - 2s 651us/sample - loss: 0.1273 - accuracy: 0.8635 - accuracy_1: 0.8635 - val_loss: 0.1331 - val_accuracy: 0.6708 - val_accuracy_1: 0.6870\n",
      "Epoch 55/200\n",
      "3781/3781 [==============================] - 2s 643us/sample - loss: 0.1275 - accuracy: 0.8609 - accuracy_1: 0.8609 - val_loss: 0.1340 - val_accuracy: 0.6052 - val_accuracy_1: 0.6764\n",
      "Epoch 56/200\n",
      "3781/3781 [==============================] - 2s 616us/sample - loss: 0.1274 - accuracy: 0.8545 - accuracy_1: 0.8545 - val_loss: 0.1402 - val_accuracy: 0.5479 - val_accuracy_1: 0.5630\n",
      "Epoch 57/200\n",
      "3781/3781 [==============================] - 2s 622us/sample - loss: 0.1270 - accuracy: 0.8529 - accuracy_1: 0.8529 - val_loss: 0.1416 - val_accuracy: 0.5708 - val_accuracy_1: 0.5986\n",
      "Epoch 58/200\n",
      "3781/3781 [==============================] - 2s 593us/sample - loss: 0.1264 - accuracy: 0.8789 - accuracy_1: 0.8789 - val_loss: 0.1424 - val_accuracy: 0.5427 - val_accuracy_1: 0.5583\n",
      "Epoch 59/200\n",
      "3781/3781 [==============================] - 2s 623us/sample - loss: 0.1266 - accuracy: 0.8797 - accuracy_1: 0.8797 - val_loss: 0.1418 - val_accuracy: 0.5385 - val_accuracy_1: 0.5634\n",
      "Epoch 60/200\n",
      "3781/3781 [==============================] - 2s 610us/sample - loss: 0.1268 - accuracy: 0.8564 - accuracy_1: 0.8564 - val_loss: 0.1404 - val_accuracy: 0.5688 - val_accuracy_1: 0.5792\n",
      "Epoch 61/200\n",
      "3781/3781 [==============================] - 2s 636us/sample - loss: 0.1267 - accuracy: 0.8715 - accuracy_1: 0.8715 - val_loss: 0.1377 - val_accuracy: 0.6135 - val_accuracy_1: 0.6292\n",
      "Epoch 62/200\n",
      "3781/3781 [==============================] - 2s 601us/sample - loss: 0.1269 - accuracy: 0.8553 - accuracy_1: 0.8553 - val_loss: 0.1380 - val_accuracy: 0.6010 - val_accuracy_1: 0.6190\n",
      "Epoch 63/200\n",
      "3781/3781 [==============================] - 2s 457us/sample - loss: 0.1261 - accuracy: 0.8892 - accuracy_1: 0.8892 - val_loss: 0.1411 - val_accuracy: 0.6083 - val_accuracy_1: 0.5806\n",
      "Epoch 64/200\n",
      "3781/3781 [==============================] - 2s 518us/sample - loss: 0.1259 - accuracy: 0.9006 - accuracy_1: 0.9006 - val_loss: 0.1437 - val_accuracy: 0.5625 - val_accuracy_1: 0.5625\n",
      "Epoch 65/200\n",
      "3781/3781 [==============================] - 2s 513us/sample - loss: 0.1263 - accuracy: 0.8855 - accuracy_1: 0.8855 - val_loss: 0.1373 - val_accuracy: 0.6104 - val_accuracy_1: 0.6139\n",
      "Epoch 66/200\n",
      "3781/3781 [==============================] - 2s 641us/sample - loss: 0.1264 - accuracy: 0.8815 - accuracy_1: 0.8815 - val_loss: 0.1404 - val_accuracy: 0.5646 - val_accuracy_1: 0.5750\n",
      "Epoch 67/200\n",
      "3781/3781 [==============================] - 2s 551us/sample - loss: 0.1262 - accuracy: 0.8659 - accuracy_1: 0.8659 - val_loss: 0.1379 - val_accuracy: 0.6021 - val_accuracy_1: 0.6333\n",
      "Epoch 68/200\n",
      "3781/3781 [==============================] - 2s 609us/sample - loss: 0.1266 - accuracy: 0.8693 - accuracy_1: 0.8693 - val_loss: 0.1388 - val_accuracy: 0.5646 - val_accuracy_1: 0.5704\n",
      "Epoch 69/200\n",
      "3781/3781 [==============================] - 2s 545us/sample - loss: 0.1260 - accuracy: 0.8860 - accuracy_1: 0.8860 - val_loss: 0.1423 - val_accuracy: 0.5583 - val_accuracy_1: 0.5769\n",
      "Epoch 70/200\n",
      "3781/3781 [==============================] - 2s 622us/sample - loss: 0.1300 - accuracy: 0.8001 - accuracy_1: 0.8001 - val_loss: 0.1381 - val_accuracy: 0.5615 - val_accuracy_1: 0.6153\n",
      "Epoch 71/200\n",
      "3781/3781 [==============================] - 2s 621us/sample - loss: 0.1304 - accuracy: 0.7506 - accuracy_1: 0.7506 - val_loss: 0.1347 - val_accuracy: 0.5615 - val_accuracy_1: 0.6431\n",
      "Epoch 72/200\n",
      "3781/3781 [==============================] - 3s 722us/sample - loss: 0.1286 - accuracy: 0.8149 - accuracy_1: 0.8149 - val_loss: 0.1342 - val_accuracy: 0.5927 - val_accuracy_1: 0.6407\n",
      "Epoch 73/200\n",
      "3781/3781 [==============================] - 2s 598us/sample - loss: 0.1277 - accuracy: 0.8448 - accuracy_1: 0.8448 - val_loss: 0.1340 - val_accuracy: 0.5958 - val_accuracy_1: 0.6653\n",
      "Epoch 74/200\n",
      "3781/3781 [==============================] - 3s 670us/sample - loss: 0.1278 - accuracy: 0.8482 - accuracy_1: 0.8482 - val_loss: 0.1342 - val_accuracy: 0.5688 - val_accuracy_1: 0.6185\n",
      "Epoch 75/200\n",
      "3781/3781 [==============================] - 3s 663us/sample - loss: 0.1275 - accuracy: 0.8440 - accuracy_1: 0.8440 - val_loss: 0.1352 - val_accuracy: 0.5969 - val_accuracy_1: 0.6657\n",
      "Epoch 76/200\n",
      "3781/3781 [==============================] - 2s 507us/sample - loss: 0.1283 - accuracy: 0.8437 - accuracy_1: 0.8437 - val_loss: 0.1369 - val_accuracy: 0.5792 - val_accuracy_1: 0.6255\n",
      "Epoch 77/200\n",
      "3781/3781 [==============================] - 2s 543us/sample - loss: 0.1273 - accuracy: 0.8617 - accuracy_1: 0.8617 - val_loss: 0.1414 - val_accuracy: 0.5740 - val_accuracy_1: 0.5745\n",
      "Epoch 78/200\n",
      "3781/3781 [==============================] - 2s 635us/sample - loss: 0.1271 - accuracy: 0.8717 - accuracy_1: 0.8717 - val_loss: 0.1362 - val_accuracy: 0.5781 - val_accuracy_1: 0.6296\n",
      "Epoch 79/200\n",
      "3781/3781 [==============================] - 2s 584us/sample - loss: 0.1268 - accuracy: 0.8696 - accuracy_1: 0.8696 - val_loss: 0.1413 - val_accuracy: 0.5552 - val_accuracy_1: 0.5870\n",
      "Epoch 80/200\n",
      "3781/3781 [==============================] - 2s 620us/sample - loss: 0.1268 - accuracy: 0.8646 - accuracy_1: 0.8646 - val_loss: 0.1371 - val_accuracy: 0.5885 - val_accuracy_1: 0.6389\n",
      "Epoch 81/200\n",
      "3781/3781 [==============================] - 2s 642us/sample - loss: 0.1268 - accuracy: 0.8820 - accuracy_1: 0.8820 - val_loss: 0.1366 - val_accuracy: 0.6010 - val_accuracy_1: 0.6468\n",
      "Epoch 82/200\n",
      "3781/3781 [==============================] - 3s 678us/sample - loss: 0.1266 - accuracy: 0.8736 - accuracy_1: 0.8736 - val_loss: 0.1357 - val_accuracy: 0.6094 - val_accuracy_1: 0.6435\n",
      "Epoch 83/200\n",
      "3781/3781 [==============================] - 2s 588us/sample - loss: 0.1269 - accuracy: 0.8614 - accuracy_1: 0.8614 - val_loss: 0.1368 - val_accuracy: 0.5813 - val_accuracy_1: 0.6380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/200\n",
      "3781/3781 [==============================] - 2s 562us/sample - loss: 0.1262 - accuracy: 0.8847 - accuracy_1: 0.8847 - val_loss: 0.1358 - val_accuracy: 0.6000 - val_accuracy_1: 0.6625\n",
      "Epoch 85/200\n",
      "3781/3781 [==============================] - 2s 503us/sample - loss: 0.1262 - accuracy: 0.8902 - accuracy_1: 0.8902 - val_loss: 0.1406 - val_accuracy: 0.6000 - val_accuracy_1: 0.6162\n",
      "Epoch 86/200\n",
      "3781/3781 [==============================] - 2s 549us/sample - loss: 0.1268 - accuracy: 0.8725 - accuracy_1: 0.8725 - val_loss: 0.1385 - val_accuracy: 0.5896 - val_accuracy_1: 0.6301\n",
      "Epoch 87/200\n",
      "3781/3781 [==============================] - 2s 507us/sample - loss: 0.1264 - accuracy: 0.8715 - accuracy_1: 0.8715 - val_loss: 0.1411 - val_accuracy: 0.5781 - val_accuracy_1: 0.6157\n",
      "Epoch 88/200\n",
      "3781/3781 [==============================] - 2s 483us/sample - loss: 0.1264 - accuracy: 0.8799 - accuracy_1: 0.8799 - val_loss: 0.1400 - val_accuracy: 0.5615 - val_accuracy_1: 0.5736\n",
      "Epoch 89/200\n",
      "3781/3781 [==============================] - 2s 535us/sample - loss: 0.1267 - accuracy: 0.8630 - accuracy_1: 0.8630 - val_loss: 0.1390 - val_accuracy: 0.5833 - val_accuracy_1: 0.6343\n",
      "Epoch 90/200\n",
      "3781/3781 [==============================] - 2s 586us/sample - loss: 0.1266 - accuracy: 0.8736 - accuracy_1: 0.8736 - val_loss: 0.1384 - val_accuracy: 0.5719 - val_accuracy_1: 0.6222\n",
      "Epoch 91/200\n",
      "3781/3781 [==============================] - 2s 528us/sample - loss: 0.1262 - accuracy: 0.8744 - accuracy_1: 0.8744 - val_loss: 0.1403 - val_accuracy: 0.5833 - val_accuracy_1: 0.5833\n",
      "Epoch 92/200\n",
      "3781/3781 [==============================] - 2s 512us/sample - loss: 0.1265 - accuracy: 0.8892 - accuracy_1: 0.8892 - val_loss: 0.1410 - val_accuracy: 0.5573 - val_accuracy_1: 0.5903\n",
      "Epoch 93/200\n",
      "3781/3781 [==============================] - 2s 523us/sample - loss: 0.1263 - accuracy: 0.8733 - accuracy_1: 0.8733 - val_loss: 0.1378 - val_accuracy: 0.5958 - val_accuracy_1: 0.6398\n",
      "Epoch 94/200\n",
      "3781/3781 [==============================] - 2s 606us/sample - loss: 0.1260 - accuracy: 0.8958 - accuracy_1: 0.8958 - val_loss: 0.1388 - val_accuracy: 0.6115 - val_accuracy_1: 0.6352\n",
      "Epoch 95/200\n",
      "3781/3781 [==============================] - 2s 567us/sample - loss: 0.1272 - accuracy: 0.8762 - accuracy_1: 0.8762 - val_loss: 0.1400 - val_accuracy: 0.5646 - val_accuracy_1: 0.5981\n",
      "Epoch 96/200\n",
      "3781/3781 [==============================] - 2s 547us/sample - loss: 0.1263 - accuracy: 0.8723 - accuracy_1: 0.8723 - val_loss: 0.1395 - val_accuracy: 0.5719 - val_accuracy_1: 0.6014\n",
      "Epoch 97/200\n",
      "3781/3781 [==============================] - 2s 530us/sample - loss: 0.1275 - accuracy: 0.8765 - accuracy_1: 0.8765 - val_loss: 0.1382 - val_accuracy: 0.5708 - val_accuracy_1: 0.5940\n",
      "Epoch 98/200\n",
      "3781/3781 [==============================] - 2s 568us/sample - loss: 0.1270 - accuracy: 0.8786 - accuracy_1: 0.8786 - val_loss: 0.1360 - val_accuracy: 0.5719 - val_accuracy_1: 0.6431\n",
      "Epoch 99/200\n",
      "3781/3781 [==============================] - 2s 549us/sample - loss: 0.1264 - accuracy: 0.8826 - accuracy_1: 0.8826 - val_loss: 0.1390 - val_accuracy: 0.5698 - val_accuracy_1: 0.6051\n",
      "Epoch 100/200\n",
      "3781/3781 [==============================] - 2s 607us/sample - loss: 0.1267 - accuracy: 0.8622 - accuracy_1: 0.8622 - val_loss: 0.1392 - val_accuracy: 0.5750 - val_accuracy_1: 0.6005\n",
      "Epoch 101/200\n",
      "3781/3781 [==============================] - 2s 604us/sample - loss: 0.1264 - accuracy: 0.8791 - accuracy_1: 0.8791 - val_loss: 0.1418 - val_accuracy: 0.5562 - val_accuracy_1: 0.5806\n",
      "Epoch 102/200\n",
      "3781/3781 [==============================] - 3s 743us/sample - loss: 0.1265 - accuracy: 0.8765 - accuracy_1: 0.8765 - val_loss: 0.1363 - val_accuracy: 0.5813 - val_accuracy_1: 0.6171\n",
      "Epoch 103/200\n",
      "3781/3781 [==============================] - 2s 611us/sample - loss: 0.1265 - accuracy: 0.8781 - accuracy_1: 0.8781 - val_loss: 0.1344 - val_accuracy: 0.6292 - val_accuracy_1: 0.6847\n",
      "Epoch 104/200\n",
      "3781/3781 [==============================] - 2s 563us/sample - loss: 0.1262 - accuracy: 0.8807 - accuracy_1: 0.8807 - val_loss: 0.1383 - val_accuracy: 0.6052 - val_accuracy_1: 0.6417\n",
      "Epoch 105/200\n",
      "3781/3781 [==============================] - 2s 632us/sample - loss: 0.1261 - accuracy: 0.8818 - accuracy_1: 0.8818 - val_loss: 0.1385 - val_accuracy: 0.5958 - val_accuracy_1: 0.6282\n",
      "Epoch 106/200\n",
      "3781/3781 [==============================] - 2s 586us/sample - loss: 0.1257 - accuracy: 0.8963 - accuracy_1: 0.8963 - val_loss: 0.1395 - val_accuracy: 0.6073 - val_accuracy_1: 0.6310\n",
      "Epoch 107/200\n",
      "3781/3781 [==============================] - 2s 583us/sample - loss: 0.1261 - accuracy: 0.8887 - accuracy_1: 0.8887 - val_loss: 0.1408 - val_accuracy: 0.5729 - val_accuracy_1: 0.5903\n",
      "Epoch 108/200\n",
      "3781/3781 [==============================] - 2s 585us/sample - loss: 0.1257 - accuracy: 0.9006 - accuracy_1: 0.9006 - val_loss: 0.1366 - val_accuracy: 0.6271 - val_accuracy_1: 0.6676\n",
      "Epoch 109/200\n",
      "3781/3781 [==============================] - 2s 661us/sample - loss: 0.1258 - accuracy: 0.9021 - accuracy_1: 0.9021 - val_loss: 0.1389 - val_accuracy: 0.5740 - val_accuracy_1: 0.6278\n",
      "Epoch 110/200\n",
      "3781/3781 [==============================] - 2s 574us/sample - loss: 0.1261 - accuracy: 0.8937 - accuracy_1: 0.8937 - val_loss: 0.1401 - val_accuracy: 0.5750 - val_accuracy_1: 0.6097\n",
      "Epoch 111/200\n",
      "3781/3781 [==============================] - 2s 499us/sample - loss: 0.1256 - accuracy: 0.9066 - accuracy_1: 0.9066 - val_loss: 0.1392 - val_accuracy: 0.5823 - val_accuracy_1: 0.6361\n",
      "Epoch 112/200\n",
      "3781/3781 [==============================] - 2s 626us/sample - loss: 0.1257 - accuracy: 0.8934 - accuracy_1: 0.8934 - val_loss: 0.1391 - val_accuracy: 0.5865 - val_accuracy_1: 0.6171\n",
      "Epoch 113/200\n",
      "3781/3781 [==============================] - 2s 618us/sample - loss: 0.1257 - accuracy: 0.8908 - accuracy_1: 0.8908 - val_loss: 0.1394 - val_accuracy: 0.5771 - val_accuracy_1: 0.6338\n",
      "Epoch 114/200\n",
      "3781/3781 [==============================] - 2s 508us/sample - loss: 0.1259 - accuracy: 0.8908 - accuracy_1: 0.8908 - val_loss: 0.1423 - val_accuracy: 0.5656 - val_accuracy_1: 0.5847\n",
      "Epoch 115/200\n",
      "3781/3781 [==============================] - 2s 523us/sample - loss: 0.1255 - accuracy: 0.9045 - accuracy_1: 0.9045 - val_loss: 0.1389 - val_accuracy: 0.5802 - val_accuracy_1: 0.6213\n",
      "Epoch 116/200\n",
      "3781/3781 [==============================] - 2s 535us/sample - loss: 0.1258 - accuracy: 0.8791 - accuracy_1: 0.8791 - val_loss: 0.1413 - val_accuracy: 0.5844 - val_accuracy_1: 0.6069\n",
      "Epoch 117/200\n",
      "3781/3781 [==============================] - 2s 524us/sample - loss: 0.1254 - accuracy: 0.9080 - accuracy_1: 0.9080 - val_loss: 0.1378 - val_accuracy: 0.6104 - val_accuracy_1: 0.6440\n",
      "Epoch 118/200\n",
      "3781/3781 [==============================] - 2s 556us/sample - loss: 0.1257 - accuracy: 0.8945 - accuracy_1: 0.8945 - val_loss: 0.1395 - val_accuracy: 0.6083 - val_accuracy_1: 0.6315\n",
      "Epoch 119/200\n",
      "3781/3781 [==============================] - 2s 562us/sample - loss: 0.1255 - accuracy: 0.9069 - accuracy_1: 0.9069 - val_loss: 0.1402 - val_accuracy: 0.6073 - val_accuracy_1: 0.6333\n",
      "Epoch 120/200\n",
      "3781/3781 [==============================] - 2s 558us/sample - loss: 0.1255 - accuracy: 0.9140 - accuracy_1: 0.9140 - val_loss: 0.1422 - val_accuracy: 0.5750 - val_accuracy_1: 0.6028\n",
      "Epoch 121/200\n",
      "3781/3781 [==============================] - 2s 590us/sample - loss: 0.1255 - accuracy: 0.9056 - accuracy_1: 0.9056 - val_loss: 0.1393 - val_accuracy: 0.5781 - val_accuracy_1: 0.6389\n",
      "Epoch 122/200\n",
      "3781/3781 [==============================] - 2s 537us/sample - loss: 0.1254 - accuracy: 0.9140 - accuracy_1: 0.9140 - val_loss: 0.1349 - val_accuracy: 0.6479 - val_accuracy_1: 0.6954\n",
      "Epoch 123/200\n",
      "3781/3781 [==============================] - 2s 587us/sample - loss: 0.1260 - accuracy: 0.9074 - accuracy_1: 0.9074 - val_loss: 0.1348 - val_accuracy: 0.6365 - val_accuracy_1: 0.7019\n",
      "Epoch 124/200\n",
      "3781/3781 [==============================] - 2s 625us/sample - loss: 0.1263 - accuracy: 0.8931 - accuracy_1: 0.8931 - val_loss: 0.1357 - val_accuracy: 0.6042 - val_accuracy_1: 0.6852\n",
      "Epoch 125/200\n",
      "3781/3781 [==============================] - 2s 645us/sample - loss: 0.1263 - accuracy: 0.8781 - accuracy_1: 0.8781 - val_loss: 0.1386 - val_accuracy: 0.5844 - val_accuracy_1: 0.6301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/200\n",
      "3781/3781 [==============================] - 2s 583us/sample - loss: 0.1255 - accuracy: 0.9069 - accuracy_1: 0.9069 - val_loss: 0.1387 - val_accuracy: 0.5833 - val_accuracy_1: 0.6319\n",
      "Epoch 127/200\n",
      "3781/3781 [==============================] - 2s 462us/sample - loss: 0.1264 - accuracy: 0.8953 - accuracy_1: 0.8953 - val_loss: 0.1341 - val_accuracy: 0.6219 - val_accuracy_1: 0.6792\n",
      "Epoch 128/200\n",
      "3781/3781 [==============================] - 2s 493us/sample - loss: 0.1264 - accuracy: 0.8900 - accuracy_1: 0.8900 - val_loss: 0.1433 - val_accuracy: 0.5469 - val_accuracy_1: 0.5787\n",
      "Epoch 129/200\n",
      "3781/3781 [==============================] - 2s 535us/sample - loss: 0.1260 - accuracy: 0.8945 - accuracy_1: 0.8945 - val_loss: 0.1380 - val_accuracy: 0.5865 - val_accuracy_1: 0.5986\n",
      "Epoch 130/200\n",
      "3781/3781 [==============================] - 2s 462us/sample - loss: 0.1258 - accuracy: 0.8998 - accuracy_1: 0.8998 - val_loss: 0.1373 - val_accuracy: 0.6292 - val_accuracy_1: 0.6593\n",
      "Epoch 131/200\n",
      "3781/3781 [==============================] - 2s 498us/sample - loss: 0.1266 - accuracy: 0.8876 - accuracy_1: 0.8876 - val_loss: 0.1333 - val_accuracy: 0.6302 - val_accuracy_1: 0.7037\n",
      "Epoch 132/200\n",
      "3781/3781 [==============================] - 2s 613us/sample - loss: 0.1266 - accuracy: 0.8794 - accuracy_1: 0.8794 - val_loss: 0.1384 - val_accuracy: 0.5885 - val_accuracy_1: 0.6412\n",
      "Epoch 133/200\n",
      "3781/3781 [==============================] - 3s 663us/sample - loss: 0.1265 - accuracy: 0.8815 - accuracy_1: 0.8815 - val_loss: 0.1363 - val_accuracy: 0.5708 - val_accuracy_1: 0.6148\n",
      "Epoch 134/200\n",
      "3781/3781 [==============================] - 3s 731us/sample - loss: 0.1262 - accuracy: 0.8908 - accuracy_1: 0.8908 - val_loss: 0.1421 - val_accuracy: 0.5437 - val_accuracy_1: 0.5819\n",
      "Epoch 135/200\n",
      "3781/3781 [==============================] - 2s 605us/sample - loss: 0.1258 - accuracy: 0.8979 - accuracy_1: 0.8979 - val_loss: 0.1406 - val_accuracy: 0.5677 - val_accuracy_1: 0.5972\n",
      "Epoch 136/200\n",
      "3781/3781 [==============================] - 3s 763us/sample - loss: 0.1258 - accuracy: 0.8900 - accuracy_1: 0.8900 - val_loss: 0.1378 - val_accuracy: 0.5979 - val_accuracy_1: 0.6315\n",
      "Epoch 137/200\n",
      "3781/3781 [==============================] - 3s 680us/sample - loss: 0.1260 - accuracy: 0.8934 - accuracy_1: 0.8934 - val_loss: 0.1376 - val_accuracy: 0.6156 - val_accuracy_1: 0.6394\n",
      "Epoch 138/200\n",
      "3781/3781 [==============================] - 3s 684us/sample - loss: 0.1253 - accuracy: 0.9101 - accuracy_1: 0.9101 - val_loss: 0.1394 - val_accuracy: 0.5781 - val_accuracy_1: 0.6204\n",
      "Epoch 139/200\n",
      "3781/3781 [==============================] - 2s 603us/sample - loss: 0.1252 - accuracy: 0.9098 - accuracy_1: 0.9098 - val_loss: 0.1478 - val_accuracy: 0.5312 - val_accuracy_1: 0.5509\n",
      "Epoch 140/200\n",
      "3781/3781 [==============================] - 2s 577us/sample - loss: 0.1326 - accuracy: 0.6498 - accuracy_1: 0.6498 - val_loss: 0.1330 - val_accuracy: 0.5938 - val_accuracy_1: 0.6528\n",
      "Epoch 141/200\n",
      "3781/3781 [==============================] - 2s 584us/sample - loss: 0.1312 - accuracy: 0.7506 - accuracy_1: 0.7506 - val_loss: 0.1320 - val_accuracy: 0.6073 - val_accuracy_1: 0.6773\n",
      "Epoch 142/200\n",
      "3781/3781 [==============================] - 2s 611us/sample - loss: 0.1287 - accuracy: 0.8165 - accuracy_1: 0.8165 - val_loss: 0.1339 - val_accuracy: 0.6062 - val_accuracy_1: 0.6769\n",
      "Epoch 143/200\n",
      "3781/3781 [==============================] - 3s 781us/sample - loss: 0.1286 - accuracy: 0.8392 - accuracy_1: 0.8392 - val_loss: 0.1329 - val_accuracy: 0.6010 - val_accuracy_1: 0.6676\n",
      "Epoch 144/200\n",
      "3781/3781 [==============================] - 3s 663us/sample - loss: 0.1288 - accuracy: 0.8366 - accuracy_1: 0.8366 - val_loss: 0.1324 - val_accuracy: 0.6208 - val_accuracy_1: 0.6856\n",
      "Epoch 145/200\n",
      "3781/3781 [==============================] - 2s 482us/sample - loss: 0.1276 - accuracy: 0.8744 - accuracy_1: 0.8744 - val_loss: 0.1331 - val_accuracy: 0.6146 - val_accuracy_1: 0.6875\n",
      "Epoch 146/200\n",
      "3781/3781 [==============================] - 2s 569us/sample - loss: 0.1276 - accuracy: 0.8720 - accuracy_1: 0.8720 - val_loss: 0.1343 - val_accuracy: 0.5969 - val_accuracy_1: 0.6681\n",
      "Epoch 147/200\n",
      "3781/3781 [==============================] - 2s 544us/sample - loss: 0.1268 - accuracy: 0.8900 - accuracy_1: 0.8900 - val_loss: 0.1338 - val_accuracy: 0.6125 - val_accuracy_1: 0.6796\n",
      "Epoch 148/200\n",
      "3781/3781 [==============================] - 2s 555us/sample - loss: 0.1266 - accuracy: 0.8934 - accuracy_1: 0.8934 - val_loss: 0.1341 - val_accuracy: 0.6302 - val_accuracy_1: 0.6898\n",
      "Epoch 149/200\n",
      "3781/3781 [==============================] - 2s 573us/sample - loss: 0.1264 - accuracy: 0.8924 - accuracy_1: 0.8924 - val_loss: 0.1341 - val_accuracy: 0.6656 - val_accuracy_1: 0.6847\n",
      "Epoch 150/200\n",
      "3781/3781 [==============================] - 2s 576us/sample - loss: 0.1260 - accuracy: 0.9111 - accuracy_1: 0.9111 - val_loss: 0.1360 - val_accuracy: 0.6104 - val_accuracy_1: 0.6694\n",
      "Epoch 151/200\n",
      "3781/3781 [==============================] - 2s 529us/sample - loss: 0.1266 - accuracy: 0.8889 - accuracy_1: 0.8889 - val_loss: 0.1354 - val_accuracy: 0.6427 - val_accuracy_1: 0.6745\n",
      "Epoch 152/200\n",
      "3781/3781 [==============================] - 2s 542us/sample - loss: 0.1260 - accuracy: 0.9056 - accuracy_1: 0.9056 - val_loss: 0.1346 - val_accuracy: 0.6271 - val_accuracy_1: 0.6861\n",
      "Epoch 153/200\n",
      "3781/3781 [==============================] - 2s 481us/sample - loss: 0.1262 - accuracy: 0.8894 - accuracy_1: 0.8894 - val_loss: 0.1360 - val_accuracy: 0.6177 - val_accuracy_1: 0.6843\n",
      "Epoch 154/200\n",
      "3781/3781 [==============================] - 2s 585us/sample - loss: 0.1260 - accuracy: 0.9013 - accuracy_1: 0.9013 - val_loss: 0.1348 - val_accuracy: 0.6125 - val_accuracy_1: 0.6796\n",
      "Epoch 155/200\n",
      "3781/3781 [==============================] - 2s 641us/sample - loss: 0.1256 - accuracy: 0.9095 - accuracy_1: 0.9095 - val_loss: 0.1368 - val_accuracy: 0.6042 - val_accuracy_1: 0.6875\n",
      "Epoch 156/200\n",
      "3781/3781 [==============================] - 2s 490us/sample - loss: 0.1257 - accuracy: 0.9080 - accuracy_1: 0.9080 - val_loss: 0.1358 - val_accuracy: 0.6156 - val_accuracy_1: 0.6787\n",
      "Epoch 157/200\n",
      "3781/3781 [==============================] - 2s 504us/sample - loss: 0.1260 - accuracy: 0.9074 - accuracy_1: 0.9074 - val_loss: 0.1386 - val_accuracy: 0.5979 - val_accuracy_1: 0.6361\n",
      "Epoch 158/200\n",
      "3781/3781 [==============================] - 2s 490us/sample - loss: 0.1266 - accuracy: 0.8958 - accuracy_1: 0.8958 - val_loss: 0.1357 - val_accuracy: 0.6073 - val_accuracy_1: 0.6657\n",
      "Epoch 159/200\n",
      "3781/3781 [==============================] - 2s 511us/sample - loss: 0.1265 - accuracy: 0.8831 - accuracy_1: 0.8831 - val_loss: 0.1365 - val_accuracy: 0.6062 - val_accuracy_1: 0.6815\n",
      "Epoch 160/200\n",
      "3781/3781 [==============================] - 2s 583us/sample - loss: 0.1255 - accuracy: 0.9045 - accuracy_1: 0.9045 - val_loss: 0.1368 - val_accuracy: 0.5990 - val_accuracy_1: 0.6690\n",
      "Epoch 161/200\n",
      "3781/3781 [==============================] - 2s 614us/sample - loss: 0.1258 - accuracy: 0.8950 - accuracy_1: 0.8950 - val_loss: 0.1358 - val_accuracy: 0.5969 - val_accuracy_1: 0.6727\n",
      "Epoch 162/200\n",
      "3781/3781 [==============================] - 3s 692us/sample - loss: 0.1255 - accuracy: 0.9085 - accuracy_1: 0.9085 - val_loss: 0.1375 - val_accuracy: 0.6021 - val_accuracy_1: 0.6634\n",
      "Epoch 163/200\n",
      "3781/3781 [==============================] - 2s 633us/sample - loss: 0.1254 - accuracy: 0.9077 - accuracy_1: 0.9077 - val_loss: 0.1350 - val_accuracy: 0.6406 - val_accuracy_1: 0.6921\n",
      "Epoch 164/200\n",
      "3781/3781 [==============================] - 2s 645us/sample - loss: 0.1275 - accuracy: 0.8736 - accuracy_1: 0.8736 - val_loss: 0.1349 - val_accuracy: 0.6187 - val_accuracy_1: 0.6870\n",
      "Epoch 165/200\n",
      "3781/3781 [==============================] - 2s 591us/sample - loss: 0.1264 - accuracy: 0.8969 - accuracy_1: 0.8969 - val_loss: 0.1342 - val_accuracy: 0.6167 - val_accuracy_1: 0.7093\n",
      "Epoch 166/200\n",
      "3781/3781 [==============================] - 2s 642us/sample - loss: 0.1271 - accuracy: 0.8871 - accuracy_1: 0.8871 - val_loss: 0.1345 - val_accuracy: 0.6208 - val_accuracy_1: 0.6810\n",
      "Epoch 167/200\n",
      "3781/3781 [==============================] - 2s 433us/sample - loss: 0.1263 - accuracy: 0.8913 - accuracy_1: 0.8913 - val_loss: 0.1353 - val_accuracy: 0.6198 - val_accuracy_1: 0.6782\n",
      "Epoch 168/200\n",
      "3781/3781 [==============================] - 2s 475us/sample - loss: 0.1269 - accuracy: 0.8762 - accuracy_1: 0.8762 - val_loss: 0.1337 - val_accuracy: 0.6167 - val_accuracy_1: 0.6861\n",
      "Epoch 169/200\n",
      "3781/3781 [==============================] - 2s 497us/sample - loss: 0.1262 - accuracy: 0.8918 - accuracy_1: 0.8918 - val_loss: 0.1342 - val_accuracy: 0.6635 - val_accuracy_1: 0.7046\n",
      "Epoch 170/200\n",
      "3781/3781 [==============================] - 2s 597us/sample - loss: 0.1261 - accuracy: 0.8984 - accuracy_1: 0.8984 - val_loss: 0.1354 - val_accuracy: 0.6208 - val_accuracy_1: 0.6602\n",
      "Epoch 171/200\n",
      "3781/3781 [==============================] - 2s 463us/sample - loss: 0.1264 - accuracy: 0.8852 - accuracy_1: 0.8852 - val_loss: 0.1349 - val_accuracy: 0.6198 - val_accuracy_1: 0.6597\n",
      "Epoch 172/200\n",
      "3781/3781 [==============================] - 2s 506us/sample - loss: 0.1262 - accuracy: 0.9024 - accuracy_1: 0.9024 - val_loss: 0.1362 - val_accuracy: 0.6010 - val_accuracy_1: 0.6514\n",
      "Epoch 173/200\n",
      "3781/3781 [==============================] - 2s 480us/sample - loss: 0.1261 - accuracy: 0.9035 - accuracy_1: 0.9035 - val_loss: 0.1355 - val_accuracy: 0.6354 - val_accuracy_1: 0.6829\n",
      "Epoch 174/200\n",
      "3781/3781 [==============================] - 2s 506us/sample - loss: 0.1264 - accuracy: 0.8902 - accuracy_1: 0.8902 - val_loss: 0.1352 - val_accuracy: 0.6229 - val_accuracy_1: 0.6704\n",
      "Epoch 175/200\n",
      "3781/3781 [==============================] - 2s 461us/sample - loss: 0.1264 - accuracy: 0.8916 - accuracy_1: 0.8916 - val_loss: 0.1349 - val_accuracy: 0.6240 - val_accuracy_1: 0.6847\n",
      "Epoch 176/200\n",
      "3781/3781 [==============================] - 2s 474us/sample - loss: 0.1260 - accuracy: 0.9006 - accuracy_1: 0.9006 - val_loss: 0.1354 - val_accuracy: 0.6375 - val_accuracy_1: 0.6907\n",
      "Epoch 177/200\n",
      "3781/3781 [==============================] - 2s 493us/sample - loss: 0.1263 - accuracy: 0.8963 - accuracy_1: 0.8963 - val_loss: 0.1355 - val_accuracy: 0.6375 - val_accuracy_1: 0.6306\n",
      "Epoch 178/200\n",
      "3781/3781 [==============================] - 2s 569us/sample - loss: 0.1286 - accuracy: 0.8418 - accuracy_1: 0.8418 - val_loss: 0.1341 - val_accuracy: 0.6062 - val_accuracy_1: 0.6907\n",
      "Epoch 179/200\n",
      "3781/3781 [==============================] - 2s 553us/sample - loss: 0.1267 - accuracy: 0.8839 - accuracy_1: 0.8839 - val_loss: 0.1348 - val_accuracy: 0.6073 - val_accuracy_1: 0.6634\n",
      "Epoch 180/200\n",
      "3781/3781 [==============================] - 2s 586us/sample - loss: 0.1260 - accuracy: 0.9106 - accuracy_1: 0.9106 - val_loss: 0.1349 - val_accuracy: 0.6229 - val_accuracy_1: 0.7051\n",
      "Epoch 181/200\n",
      "3781/3781 [==============================] - 2s 571us/sample - loss: 0.1260 - accuracy: 0.9019 - accuracy_1: 0.9019 - val_loss: 0.1350 - val_accuracy: 0.6260 - val_accuracy_1: 0.6810\n",
      "Epoch 182/200\n",
      "3781/3781 [==============================] - 2s 615us/sample - loss: 0.1258 - accuracy: 0.9140 - accuracy_1: 0.9140 - val_loss: 0.1356 - val_accuracy: 0.6083 - val_accuracy_1: 0.6940\n",
      "Epoch 183/200\n",
      "3781/3781 [==============================] - 2s 529us/sample - loss: 0.1262 - accuracy: 0.9006 - accuracy_1: 0.9006 - val_loss: 0.1351 - val_accuracy: 0.6208 - val_accuracy_1: 0.6833\n",
      "Epoch 184/200\n",
      "3781/3781 [==============================] - 2s 597us/sample - loss: 0.1264 - accuracy: 0.8897 - accuracy_1: 0.8897 - val_loss: 0.1340 - val_accuracy: 0.6177 - val_accuracy_1: 0.6843\n",
      "Epoch 185/200\n",
      "3781/3781 [==============================] - 2s 546us/sample - loss: 0.1266 - accuracy: 0.8876 - accuracy_1: 0.8876 - val_loss: 0.1345 - val_accuracy: 0.6417 - val_accuracy_1: 0.6718\n",
      "Epoch 186/200\n",
      "3781/3781 [==============================] - 2s 518us/sample - loss: 0.1265 - accuracy: 0.8865 - accuracy_1: 0.8865 - val_loss: 0.1355 - val_accuracy: 0.6240 - val_accuracy_1: 0.6870\n",
      "Epoch 187/200\n",
      "3781/3781 [==============================] - 2s 554us/sample - loss: 0.1262 - accuracy: 0.8974 - accuracy_1: 0.8974 - val_loss: 0.1345 - val_accuracy: 0.6250 - val_accuracy_1: 0.6991\n",
      "Epoch 188/200\n",
      "3781/3781 [==============================] - 2s 556us/sample - loss: 0.1262 - accuracy: 0.8921 - accuracy_1: 0.8921 - val_loss: 0.1358 - val_accuracy: 0.6156 - val_accuracy_1: 0.6764\n",
      "Epoch 189/200\n",
      "3781/3781 [==============================] - 3s 669us/sample - loss: 0.1260 - accuracy: 0.9061 - accuracy_1: 0.9061 - val_loss: 0.1342 - val_accuracy: 0.6375 - val_accuracy_1: 0.6977\n",
      "Epoch 190/200\n",
      "3781/3781 [==============================] - 2s 615us/sample - loss: 0.1267 - accuracy: 0.8723 - accuracy_1: 0.8723 - val_loss: 0.1348 - val_accuracy: 0.6208 - val_accuracy_1: 0.6833\n",
      "Epoch 191/200\n",
      "3781/3781 [==============================] - 3s 669us/sample - loss: 0.1261 - accuracy: 0.8969 - accuracy_1: 0.8969 - val_loss: 0.1359 - val_accuracy: 0.6167 - val_accuracy_1: 0.6977\n",
      "Epoch 192/200\n",
      "3781/3781 [==============================] - 2s 632us/sample - loss: 0.1263 - accuracy: 0.9056 - accuracy_1: 0.9056 - val_loss: 0.1347 - val_accuracy: 0.6146 - val_accuracy_1: 0.6852\n",
      "Epoch 193/200\n",
      "3781/3781 [==============================] - 2s 510us/sample - loss: 0.1260 - accuracy: 0.9040 - accuracy_1: 0.9040 - val_loss: 0.1341 - val_accuracy: 0.6365 - val_accuracy_1: 0.6972\n",
      "Epoch 194/200\n",
      "3781/3781 [==============================] - 2s 547us/sample - loss: 0.1260 - accuracy: 0.9035 - accuracy_1: 0.9035 - val_loss: 0.1363 - val_accuracy: 0.6177 - val_accuracy_1: 0.6796\n",
      "Epoch 195/200\n",
      "3781/3781 [==============================] - 2s 569us/sample - loss: 0.1285 - accuracy: 0.8635 - accuracy_1: 0.8635 - val_loss: 0.1337 - val_accuracy: 0.5969 - val_accuracy_1: 0.6727\n",
      "Epoch 196/200\n",
      "3781/3781 [==============================] - 2s 566us/sample - loss: 0.1259 - accuracy: 0.9111 - accuracy_1: 0.9111 - val_loss: 0.1351 - val_accuracy: 0.6156 - val_accuracy_1: 0.6556\n",
      "Epoch 197/200\n",
      "3781/3781 [==============================] - 2s 544us/sample - loss: 0.1259 - accuracy: 0.9040 - accuracy_1: 0.9040 - val_loss: 0.1349 - val_accuracy: 0.6229 - val_accuracy_1: 0.6727\n",
      "Epoch 198/200\n",
      "3781/3781 [==============================] - 2s 564us/sample - loss: 0.1261 - accuracy: 0.9003 - accuracy_1: 0.9003 - val_loss: 0.1351 - val_accuracy: 0.6344 - val_accuracy_1: 0.6963\n",
      "Epoch 199/200\n",
      "3781/3781 [==============================] - 2s 495us/sample - loss: 0.1260 - accuracy: 0.9117 - accuracy_1: 0.9117 - val_loss: 0.1352 - val_accuracy: 0.6229 - val_accuracy_1: 0.6912\n",
      "Epoch 200/200\n",
      "3781/3781 [==============================] - 2s 653us/sample - loss: 0.1259 - accuracy: 0.9035 - accuracy_1: 0.9035 - val_loss: 0.1359 - val_accuracy: 0.6146 - val_accuracy_1: 0.6736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f38f0407710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using focal loss\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def focal_loss(classes_num, gamma=1, alpha=1, e=0.1):\n",
    "    # classes_num contains sample number of each classes\n",
    "    def focal_loss_fixed(target_tensor, prediction_tensor):\n",
    "        '''\n",
    "        prediction_tensor is the output tensor with shape [None, 100], where 100 is the number of classes\n",
    "        target_tensor is the label tensor, same shape as predcition_tensor\n",
    "        '''\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.python.ops import array_ops\n",
    "        from tensorflow.keras import backend as K\n",
    "\n",
    "        #1# get focal loss with no balanced weight which presented in paper function (4)\n",
    "        zeros = array_ops.zeros_like(prediction_tensor, dtype=prediction_tensor.dtype)\n",
    "        one_minus_p = array_ops.where(tf.greater(target_tensor,zeros), target_tensor - prediction_tensor, zeros)\n",
    "        FT = -1 * (one_minus_p ** gamma) * tf.math.log(tf.clip_by_value(prediction_tensor, 1e-8, 1.0))\n",
    "\n",
    "        #2# get balanced weight alpha\n",
    "        classes_weight = array_ops.zeros_like(prediction_tensor, dtype=prediction_tensor.dtype)\n",
    "\n",
    "        total_num = float(sum(classes_num))\n",
    "        classes_w_t1 = [ total_num / ff for ff in classes_num ]\n",
    "        sum_ = sum(classes_w_t1)\n",
    "        classes_w_t2 = [ ff/sum_ for ff in classes_w_t1 ]   #scale\n",
    "        classes_w_tensor = tf.convert_to_tensor(classes_w_t2, dtype=prediction_tensor.dtype)\n",
    "        classes_weight += classes_w_tensor\n",
    "\n",
    "        alpha = array_ops.where(tf.greater(target_tensor, zeros), classes_weight, zeros)\n",
    "\n",
    "        #3# get balanced focal loss\n",
    "        balanced_fl = alpha * FT\n",
    "        balanced_fl = tf.reduce_mean(balanced_fl)\n",
    "\n",
    "        #4# add other op to prevent overfit\n",
    "        # reference : https://spaces.ac.cn/archives/4493\n",
    "        nb_classes = len(classes_num)\n",
    "        fianal_loss = (1-e) * balanced_fl + e * K.categorical_crossentropy(K.ones_like(prediction_tensor)/nb_classes, prediction_tensor)\n",
    "\n",
    "        return fianal_loss\n",
    "    return focal_loss_fixed\n",
    "\n",
    "    \n",
    "# Recompile the model\n",
    "# model.load_weights('my_model_weights.h5')\n",
    "model.compile(\n",
    "#     loss='categorical_crossentropy', \n",
    "    loss= focal_loss([600,3600,600],gamma=2, alpha=.25),\n",
    "              optimizer='Adam', metrics=['accuracy'],\n",
    "              weighted_metrics=['accuracy'])\n",
    "earlier = EarlyStopping(monitor = 'val_accuracy',mode='max',min_delta=1e-3,patience=50,verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath='best.hdf5',verbose=1, save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "\n",
    "# class_weight = {0 : 2., 1: 5.,2:1.}\n",
    "model.fit(X_train, Y_train, epochs=200, batch_size=90,\n",
    "#           class_weight=class_weight)\n",
    "          validation_data=(X_val, Y_val,val_sample_weights),\n",
    "#           callbacks=[earlier, checkpointer])\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('my_model_weights_focal.h5')\n",
    "Y_test = model.predict_classes(X_test)\n",
    "print(Y_test)\n",
    "\n",
    "\n",
    "f = open(\"best_focal_1.csv\", \"w\")\n",
    "f.write(\"id,y\\n\")\n",
    "for i,x in enumerate(Y_test):\n",
    "    f.write(\"{},{}\\n\".format(i,x))\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3781 samples, validate on 960 samples\n",
      "Epoch 1/50\n",
      "3781/3781 [==============================] - 3s 841us/sample - loss: 0.3097 - accuracy: 0.9294 - val_loss: 1.3948 - val_accuracy: 0.6521\n",
      "Epoch 2/50\n",
      "3781/3781 [==============================] - 2s 644us/sample - loss: 0.1729 - accuracy: 0.9410 - val_loss: 1.1287 - val_accuracy: 0.6469\n",
      "Epoch 3/50\n",
      "3781/3781 [==============================] - 2s 615us/sample - loss: 0.1465 - accuracy: 0.9450 - val_loss: 1.3818 - val_accuracy: 0.6458\n",
      "Epoch 4/50\n",
      "3781/3781 [==============================] - 2s 543us/sample - loss: 0.1615 - accuracy: 0.9389 - val_loss: 1.2903 - val_accuracy: 0.6729\n",
      "Epoch 5/50\n",
      "3781/3781 [==============================] - 3s 681us/sample - loss: 0.1568 - accuracy: 0.9426 - val_loss: 1.4017 - val_accuracy: 0.6521\n",
      "Epoch 6/50\n",
      "3781/3781 [==============================] - 2s 599us/sample - loss: 0.1432 - accuracy: 0.9458 - val_loss: 1.3619 - val_accuracy: 0.6323\n",
      "Epoch 7/50\n",
      "3781/3781 [==============================] - 2s 623us/sample - loss: 0.1524 - accuracy: 0.9408 - val_loss: 1.3533 - val_accuracy: 0.6656\n",
      "Epoch 8/50\n",
      "3781/3781 [==============================] - 2s 592us/sample - loss: 0.1607 - accuracy: 0.9405 - val_loss: 1.8036 - val_accuracy: 0.6531\n",
      "Epoch 9/50\n",
      "3781/3781 [==============================] - 2s 606us/sample - loss: 0.1503 - accuracy: 0.9421 - val_loss: 1.2718 - val_accuracy: 0.6927\n",
      "Epoch 10/50\n",
      "3781/3781 [==============================] - 3s 733us/sample - loss: 0.1437 - accuracy: 0.9431 - val_loss: 1.1241 - val_accuracy: 0.7021\n",
      "Epoch 11/50\n",
      "3781/3781 [==============================] - 3s 758us/sample - loss: 0.1596 - accuracy: 0.9373 - val_loss: 1.7466 - val_accuracy: 0.6469\n",
      "Epoch 12/50\n",
      "3781/3781 [==============================] - 2s 606us/sample - loss: 0.1401 - accuracy: 0.9455 - val_loss: 2.0261 - val_accuracy: 0.6823\n",
      "Epoch 13/50\n",
      "3781/3781 [==============================] - 3s 661us/sample - loss: 0.1451 - accuracy: 0.9453 - val_loss: 1.0677 - val_accuracy: 0.7417\n",
      "Epoch 14/50\n",
      "3781/3781 [==============================] - 2s 602us/sample - loss: 0.1515 - accuracy: 0.9368 - val_loss: 1.5667 - val_accuracy: 0.6510\n",
      "Epoch 15/50\n",
      "3781/3781 [==============================] - 2s 602us/sample - loss: 0.1552 - accuracy: 0.9384 - val_loss: 1.1505 - val_accuracy: 0.6646\n",
      "Epoch 16/50\n",
      "3781/3781 [==============================] - 2s 643us/sample - loss: 0.1417 - accuracy: 0.9431 - val_loss: 1.9295 - val_accuracy: 0.6687\n",
      "Epoch 17/50\n",
      "3781/3781 [==============================] - 2s 579us/sample - loss: 0.1526 - accuracy: 0.9400 - val_loss: 1.1484 - val_accuracy: 0.6948\n",
      "Epoch 18/50\n",
      "3781/3781 [==============================] - 2s 586us/sample - loss: 0.1918 - accuracy: 0.9273 - val_loss: 1.3311 - val_accuracy: 0.6687\n",
      "Epoch 19/50\n",
      "3781/3781 [==============================] - 2s 589us/sample - loss: 0.1768 - accuracy: 0.9296 - val_loss: 1.0043 - val_accuracy: 0.6833\n",
      "Epoch 20/50\n",
      "3781/3781 [==============================] - 2s 587us/sample - loss: 0.1639 - accuracy: 0.9320 - val_loss: 1.4290 - val_accuracy: 0.6521\n",
      "Epoch 21/50\n",
      "3781/3781 [==============================] - 2s 619us/sample - loss: 0.1623 - accuracy: 0.9349 - val_loss: 0.9003 - val_accuracy: 0.6760\n",
      "Epoch 22/50\n",
      "3781/3781 [==============================] - 2s 656us/sample - loss: 0.1563 - accuracy: 0.9360 - val_loss: 2.5427 - val_accuracy: 0.6469\n",
      "Epoch 23/50\n",
      "3781/3781 [==============================] - 2s 579us/sample - loss: 0.1404 - accuracy: 0.9400 - val_loss: 1.7146 - val_accuracy: 0.6615\n",
      "Epoch 24/50\n",
      "3781/3781 [==============================] - 2s 539us/sample - loss: 0.1625 - accuracy: 0.9368 - val_loss: 1.1993 - val_accuracy: 0.6771\n",
      "Epoch 25/50\n",
      "3781/3781 [==============================] - 2s 503us/sample - loss: 0.1554 - accuracy: 0.9365 - val_loss: 1.0191 - val_accuracy: 0.6698\n",
      "Epoch 26/50\n",
      "3781/3781 [==============================] - 2s 537us/sample - loss: 0.1614 - accuracy: 0.9323 - val_loss: 1.1286 - val_accuracy: 0.6615\n",
      "Epoch 27/50\n",
      "3781/3781 [==============================] - 2s 494us/sample - loss: 0.1549 - accuracy: 0.9373 - val_loss: 1.1915 - val_accuracy: 0.6760\n",
      "Epoch 28/50\n",
      "3781/3781 [==============================] - 2s 575us/sample - loss: 0.1473 - accuracy: 0.9421 - val_loss: 1.0623 - val_accuracy: 0.7104\n",
      "Epoch 29/50\n",
      "3781/3781 [==============================] - 2s 602us/sample - loss: 0.1474 - accuracy: 0.9415 - val_loss: 1.0141 - val_accuracy: 0.6875\n",
      "Epoch 30/50\n",
      "3781/3781 [==============================] - 2s 656us/sample - loss: 0.1705 - accuracy: 0.9312 - val_loss: 1.0235 - val_accuracy: 0.6490\n",
      "Epoch 31/50\n",
      "3781/3781 [==============================] - 2s 556us/sample - loss: 0.1426 - accuracy: 0.9453 - val_loss: 1.3527 - val_accuracy: 0.6990\n",
      "Epoch 32/50\n",
      "3781/3781 [==============================] - 2s 641us/sample - loss: 0.1464 - accuracy: 0.9437 - val_loss: 1.4528 - val_accuracy: 0.7021\n",
      "Epoch 33/50\n",
      "3781/3781 [==============================] - 2s 651us/sample - loss: 0.1534 - accuracy: 0.9410 - val_loss: 1.4170 - val_accuracy: 0.6708\n",
      "Epoch 34/50\n",
      "3781/3781 [==============================] - 3s 667us/sample - loss: 0.1623 - accuracy: 0.9365 - val_loss: 1.3804 - val_accuracy: 0.6708\n",
      "Epoch 35/50\n",
      "3781/3781 [==============================] - 3s 757us/sample - loss: 0.1566 - accuracy: 0.9400 - val_loss: 1.1665 - val_accuracy: 0.6969\n",
      "Epoch 36/50\n",
      "3781/3781 [==============================] - 2s 609us/sample - loss: 0.1394 - accuracy: 0.9447 - val_loss: 1.4888 - val_accuracy: 0.6479\n",
      "Epoch 37/50\n",
      "3781/3781 [==============================] - 3s 710us/sample - loss: 0.1351 - accuracy: 0.9431 - val_loss: 1.5849 - val_accuracy: 0.6625\n",
      "Epoch 38/50\n",
      "3781/3781 [==============================] - 2s 573us/sample - loss: 0.1297 - accuracy: 0.9476 - val_loss: 1.8571 - val_accuracy: 0.6625\n",
      "Epoch 39/50\n",
      "3781/3781 [==============================] - 2s 632us/sample - loss: 0.1386 - accuracy: 0.9421 - val_loss: 1.4145 - val_accuracy: 0.7073\n",
      "Epoch 40/50\n",
      "3781/3781 [==============================] - 3s 676us/sample - loss: 0.1472 - accuracy: 0.9381 - val_loss: 1.2048 - val_accuracy: 0.6823\n",
      "Epoch 41/50\n",
      "3781/3781 [==============================] - 3s 774us/sample - loss: 0.1712 - accuracy: 0.9262 - val_loss: 1.4012 - val_accuracy: 0.6854\n",
      "Epoch 42/50\n",
      "3781/3781 [==============================] - 3s 721us/sample - loss: 0.1409 - accuracy: 0.9408 - val_loss: 1.6329 - val_accuracy: 0.6698\n",
      "Epoch 43/50\n",
      "3781/3781 [==============================] - 2s 625us/sample - loss: 0.1541 - accuracy: 0.9355 - val_loss: 2.1680 - val_accuracy: 0.6844\n",
      "Epoch 44/50\n",
      "3781/3781 [==============================] - 2s 652us/sample - loss: 0.1569 - accuracy: 0.9339 - val_loss: 1.4498 - val_accuracy: 0.7135\n",
      "Epoch 45/50\n",
      "3781/3781 [==============================] - 2s 596us/sample - loss: 0.1571 - accuracy: 0.9357 - val_loss: 1.5892 - val_accuracy: 0.7052\n",
      "Epoch 46/50\n",
      "3781/3781 [==============================] - 2s 560us/sample - loss: 0.1670 - accuracy: 0.9304 - val_loss: 2.0077 - val_accuracy: 0.6656\n",
      "Epoch 47/50\n",
      "3781/3781 [==============================] - 2s 645us/sample - loss: 0.1467 - accuracy: 0.9394 - val_loss: 1.4329 - val_accuracy: 0.6906\n",
      "Epoch 48/50\n",
      "3781/3781 [==============================] - 2s 598us/sample - loss: 0.1444 - accuracy: 0.9389 - val_loss: 1.6350 - val_accuracy: 0.6906\n",
      "Epoch 49/50\n",
      "3781/3781 [==============================] - 2s 528us/sample - loss: 0.1313 - accuracy: 0.9431 - val_loss: 2.2262 - val_accuracy: 0.6812\n",
      "Epoch 50/50\n",
      "3781/3781 [==============================] - 2s 601us/sample - loss: 0.1538 - accuracy: 0.9341 - val_loss: 1.5488 - val_accuracy: 0.6750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f38b06e9d10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='Adam', metrics=['accuracy'])\n",
    "earlier = EarlyStopping(monitor = 'val_accuracy',mode='max',min_delta=1e-3,patience=50,verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath='best.hdf5',verbose=1, save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=90, validation_data=(X_val, Y_val,val_sample_weights)\n",
    "#           , callbacks=[earlier, checkpointer])\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('my_model_weights_mixed_1.h5')\n",
    "Y_test = model.predict_classes(X_test)\n",
    "print(Y_test)\n",
    "\n",
    "\n",
    "f = open(\"best_focal_mixed_2.csv\", \"w\")\n",
    "f.write(\"id,y\\n\")\n",
    "for i,x in enumerate(Y_test):\n",
    "    f.write(\"{},{}\\n\".format(i,x))\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3781 samples, validate on 960 samples\n",
      "Epoch 1/100\n",
      "3781/3781 [==============================] - 4s 1ms/sample - loss: 0.1792 - accuracy: 0.5993 - accuracy_1: 0.5993 - val_loss: 0.1169 - val_accuracy: 0.5542 - val_accuracy_1: 0.6190\n",
      "Epoch 2/100\n",
      "3781/3781 [==============================] - 3s 844us/sample - loss: 0.1162 - accuracy: 0.7054 - accuracy_1: 0.7054 - val_loss: 0.1168 - val_accuracy: 0.5927 - val_accuracy_1: 0.6454\n",
      "Epoch 3/100\n",
      "3781/3781 [==============================] - 3s 862us/sample - loss: 0.1157 - accuracy: 0.8141 - accuracy_1: 0.8141 - val_loss: 0.1171 - val_accuracy: 0.6042 - val_accuracy_1: 0.6505\n",
      "Epoch 4/100\n",
      "3781/3781 [==============================] - 3s 781us/sample - loss: 0.1153 - accuracy: 0.8649 - accuracy_1: 0.8649 - val_loss: 0.1171 - val_accuracy: 0.6031 - val_accuracy_1: 0.6222\n",
      "Epoch 5/100\n",
      "3781/3781 [==============================] - 3s 783us/sample - loss: 0.1151 - accuracy: 0.8945 - accuracy_1: 0.8945 - val_loss: 0.1171 - val_accuracy: 0.6417 - val_accuracy_1: 0.6810\n",
      "Epoch 6/100\n",
      "3781/3781 [==============================] - 3s 724us/sample - loss: 0.1149 - accuracy: 0.9035 - accuracy_1: 0.9035 - val_loss: 0.1173 - val_accuracy: 0.6302 - val_accuracy_1: 0.6690\n",
      "Epoch 7/100\n",
      "3781/3781 [==============================] - 2s 660us/sample - loss: 0.1149 - accuracy: 0.9058 - accuracy_1: 0.9058 - val_loss: 0.1178 - val_accuracy: 0.5885 - val_accuracy_1: 0.6042\n",
      "Epoch 8/100\n",
      "3781/3781 [==============================] - 3s 723us/sample - loss: 0.1149 - accuracy: 0.8971 - accuracy_1: 0.8971 - val_loss: 0.1175 - val_accuracy: 0.6125 - val_accuracy_1: 0.6218\n",
      "Epoch 9/100\n",
      "3781/3781 [==============================] - 3s 735us/sample - loss: 0.1147 - accuracy: 0.9180 - accuracy_1: 0.9180 - val_loss: 0.1180 - val_accuracy: 0.6104 - val_accuracy_1: 0.6255\n",
      "Epoch 10/100\n",
      "3781/3781 [==============================] - 3s 833us/sample - loss: 0.1146 - accuracy: 0.9222 - accuracy_1: 0.9222 - val_loss: 0.1177 - val_accuracy: 0.6187 - val_accuracy_1: 0.6546\n",
      "Epoch 11/100\n",
      "3781/3781 [==============================] - 3s 839us/sample - loss: 0.1146 - accuracy: 0.9196 - accuracy_1: 0.9196 - val_loss: 0.1181 - val_accuracy: 0.6094 - val_accuracy_1: 0.6319\n",
      "Epoch 12/100\n",
      "3781/3781 [==============================] - 3s 771us/sample - loss: 0.1148 - accuracy: 0.9056 - accuracy_1: 0.9056 - val_loss: 0.1177 - val_accuracy: 0.6198 - val_accuracy_1: 0.6620\n",
      "Epoch 13/100\n",
      "3781/3781 [==============================] - 4s 971us/sample - loss: 0.1146 - accuracy: 0.9196 - accuracy_1: 0.9196 - val_loss: 0.1182 - val_accuracy: 0.6177 - val_accuracy_1: 0.6310\n",
      "Epoch 14/100\n",
      "3781/3781 [==============================] - 3s 733us/sample - loss: 0.1146 - accuracy: 0.9228 - accuracy_1: 0.9228 - val_loss: 0.1184 - val_accuracy: 0.6229 - val_accuracy_1: 0.6333\n",
      "Epoch 15/100\n",
      "3781/3781 [==============================] - 3s 721us/sample - loss: 0.1147 - accuracy: 0.9127 - accuracy_1: 0.9127 - val_loss: 0.1183 - val_accuracy: 0.6292 - val_accuracy_1: 0.6245\n",
      "Epoch 16/100\n",
      "3781/3781 [==============================] - 3s 768us/sample - loss: 0.1146 - accuracy: 0.9281 - accuracy_1: 0.9281 - val_loss: 0.1180 - val_accuracy: 0.6406 - val_accuracy_1: 0.6597\n",
      "Epoch 17/100\n",
      "3781/3781 [==============================] - 3s 738us/sample - loss: 0.1145 - accuracy: 0.9294 - accuracy_1: 0.9294 - val_loss: 0.1178 - val_accuracy: 0.6167 - val_accuracy_1: 0.6468\n",
      "Epoch 18/100\n",
      "3781/3781 [==============================] - 3s 850us/sample - loss: 0.1145 - accuracy: 0.9344 - accuracy_1: 0.9344 - val_loss: 0.1178 - val_accuracy: 0.6167 - val_accuracy_1: 0.6676\n",
      "Epoch 19/100\n",
      "3781/3781 [==============================] - 3s 718us/sample - loss: 0.1147 - accuracy: 0.9095 - accuracy_1: 0.9095 - val_loss: 0.1174 - val_accuracy: 0.6427 - val_accuracy_1: 0.6815\n",
      "Epoch 20/100\n",
      "3781/3781 [==============================] - 3s 731us/sample - loss: 0.1147 - accuracy: 0.9236 - accuracy_1: 0.9236 - val_loss: 0.1176 - val_accuracy: 0.6313 - val_accuracy_1: 0.6856\n",
      "Epoch 21/100\n",
      "3781/3781 [==============================] - 3s 669us/sample - loss: 0.1148 - accuracy: 0.9125 - accuracy_1: 0.9125 - val_loss: 0.1176 - val_accuracy: 0.6125 - val_accuracy_1: 0.6634\n",
      "Epoch 22/100\n",
      "3781/3781 [==============================] - 3s 771us/sample - loss: 0.1146 - accuracy: 0.9199 - accuracy_1: 0.9199 - val_loss: 0.1177 - val_accuracy: 0.6156 - val_accuracy_1: 0.6602\n",
      "Epoch 23/100\n",
      "3781/3781 [==============================] - 3s 812us/sample - loss: 0.1146 - accuracy: 0.9138 - accuracy_1: 0.9138 - val_loss: 0.1178 - val_accuracy: 0.6156 - val_accuracy_1: 0.6671\n",
      "Epoch 24/100\n",
      "3781/3781 [==============================] - 3s 865us/sample - loss: 0.1145 - accuracy: 0.9225 - accuracy_1: 0.9225 - val_loss: 0.1178 - val_accuracy: 0.6365 - val_accuracy_1: 0.6602\n",
      "Epoch 25/100\n",
      "3781/3781 [==============================] - 4s 996us/sample - loss: 0.1145 - accuracy: 0.9328 - accuracy_1: 0.9328 - val_loss: 0.1177 - val_accuracy: 0.6479 - val_accuracy_1: 0.6745\n",
      "Epoch 26/100\n",
      "3781/3781 [==============================] - 3s 829us/sample - loss: 0.1145 - accuracy: 0.9352 - accuracy_1: 0.9352 - val_loss: 0.1182 - val_accuracy: 0.6302 - val_accuracy_1: 0.6366\n",
      "Epoch 27/100\n",
      "3781/3781 [==============================] - 4s 972us/sample - loss: 0.1145 - accuracy: 0.9328 - accuracy_1: 0.9328 - val_loss: 0.1180 - val_accuracy: 0.6229 - val_accuracy_1: 0.6565\n",
      "Epoch 28/100\n",
      "3781/3781 [==============================] - 3s 893us/sample - loss: 0.1145 - accuracy: 0.9331 - accuracy_1: 0.9331 - val_loss: 0.1181 - val_accuracy: 0.6208 - val_accuracy_1: 0.6694\n",
      "Epoch 29/100\n",
      "3781/3781 [==============================] - 3s 856us/sample - loss: 0.1146 - accuracy: 0.9225 - accuracy_1: 0.9225 - val_loss: 0.1176 - val_accuracy: 0.6479 - val_accuracy_1: 0.6722\n",
      "Epoch 30/100\n",
      "3781/3781 [==============================] - 4s 979us/sample - loss: 0.1145 - accuracy: 0.9299 - accuracy_1: 0.9299 - val_loss: 0.1181 - val_accuracy: 0.6240 - val_accuracy_1: 0.6593\n",
      "Epoch 31/100\n",
      "3781/3781 [==============================] - 3s 924us/sample - loss: 0.1146 - accuracy: 0.9122 - accuracy_1: 0.9122 - val_loss: 0.1176 - val_accuracy: 0.6219 - val_accuracy_1: 0.6884\n",
      "Epoch 32/100\n",
      "3781/3781 [==============================] - 4s 978us/sample - loss: 0.1145 - accuracy: 0.9193 - accuracy_1: 0.9193 - val_loss: 0.1177 - val_accuracy: 0.6302 - val_accuracy_1: 0.6759\n",
      "Epoch 33/100\n",
      "3781/3781 [==============================] - 4s 992us/sample - loss: 0.1146 - accuracy: 0.9183 - accuracy_1: 0.9183 - val_loss: 0.1175 - val_accuracy: 0.6448 - val_accuracy_1: 0.7079\n",
      "Epoch 34/100\n",
      "3781/3781 [==============================] - 4s 978us/sample - loss: 0.1146 - accuracy: 0.9199 - accuracy_1: 0.9199 - val_loss: 0.1178 - val_accuracy: 0.6375 - val_accuracy_1: 0.6606\n",
      "Epoch 35/100\n",
      "3781/3781 [==============================] - 3s 670us/sample - loss: 0.1146 - accuracy: 0.9289 - accuracy_1: 0.9289 - val_loss: 0.1172 - val_accuracy: 0.6604 - val_accuracy_1: 0.7056\n",
      "Epoch 36/100\n",
      "3781/3781 [==============================] - 3s 908us/sample - loss: 0.1145 - accuracy: 0.9360 - accuracy_1: 0.9360 - val_loss: 0.1175 - val_accuracy: 0.6719 - val_accuracy_1: 0.6944\n",
      "Epoch 37/100\n",
      "3781/3781 [==============================] - 3s 869us/sample - loss: 0.1146 - accuracy: 0.9267 - accuracy_1: 0.9267 - val_loss: 0.1177 - val_accuracy: 0.6323 - val_accuracy_1: 0.6560\n",
      "Epoch 38/100\n",
      "3781/3781 [==============================] - 3s 849us/sample - loss: 0.1145 - accuracy: 0.9328 - accuracy_1: 0.9328 - val_loss: 0.1181 - val_accuracy: 0.6250 - val_accuracy_1: 0.6505\n",
      "Epoch 39/100\n",
      "3781/3781 [==============================] - 3s 801us/sample - loss: 0.1146 - accuracy: 0.9302 - accuracy_1: 0.9302 - val_loss: 0.1176 - val_accuracy: 0.6250 - val_accuracy_1: 0.6852\n",
      "Epoch 40/100\n",
      "3781/3781 [==============================] - 4s 958us/sample - loss: 0.1145 - accuracy: 0.9281 - accuracy_1: 0.9281 - val_loss: 0.1178 - val_accuracy: 0.6427 - val_accuracy_1: 0.7046\n",
      "Epoch 41/100\n",
      "3781/3781 [==============================] - 3s 864us/sample - loss: 0.1146 - accuracy: 0.9323 - accuracy_1: 0.9323 - val_loss: 0.1174 - val_accuracy: 0.6000 - val_accuracy_1: 0.5931\n",
      "Epoch 42/100\n",
      "3781/3781 [==============================] - 4s 956us/sample - loss: 0.1147 - accuracy: 0.9193 - accuracy_1: 0.9193 - val_loss: 0.1175 - val_accuracy: 0.6292 - val_accuracy_1: 0.6986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "3781/3781 [==============================] - 3s 835us/sample - loss: 0.1147 - accuracy: 0.9185 - accuracy_1: 0.9185 - val_loss: 0.1174 - val_accuracy: 0.6521 - val_accuracy_1: 0.7019\n",
      "Epoch 44/100\n",
      "3781/3781 [==============================] - 3s 923us/sample - loss: 0.1146 - accuracy: 0.9267 - accuracy_1: 0.9267 - val_loss: 0.1175 - val_accuracy: 0.6458 - val_accuracy_1: 0.7037\n",
      "Epoch 45/100\n",
      "3781/3781 [==============================] - 4s 1ms/sample - loss: 0.1145 - accuracy: 0.9257 - accuracy_1: 0.9257 - val_loss: 0.1177 - val_accuracy: 0.6708 - val_accuracy_1: 0.6662\n",
      "Epoch 46/100\n",
      "3781/3781 [==============================] - 3s 903us/sample - loss: 0.1145 - accuracy: 0.9296 - accuracy_1: 0.9296 - val_loss: 0.1178 - val_accuracy: 0.6208 - val_accuracy_1: 0.6579\n",
      "Epoch 47/100\n",
      "3781/3781 [==============================] - 3s 805us/sample - loss: 0.1145 - accuracy: 0.9334 - accuracy_1: 0.9334 - val_loss: 0.1177 - val_accuracy: 0.6229 - val_accuracy_1: 0.6727\n",
      "Epoch 48/100\n",
      "3781/3781 [==============================] - 2s 633us/sample - loss: 0.1146 - accuracy: 0.9225 - accuracy_1: 0.9225 - val_loss: 0.1175 - val_accuracy: 0.6521 - val_accuracy_1: 0.6949\n",
      "Epoch 49/100\n",
      "3781/3781 [==============================] - 3s 686us/sample - loss: 0.1144 - accuracy: 0.9357 - accuracy_1: 0.9357 - val_loss: 0.1178 - val_accuracy: 0.6427 - val_accuracy_1: 0.6907\n",
      "Epoch 50/100\n",
      "3781/3781 [==============================] - 3s 747us/sample - loss: 0.1147 - accuracy: 0.9209 - accuracy_1: 0.9209 - val_loss: 0.1175 - val_accuracy: 0.6375 - val_accuracy_1: 0.6884\n",
      "Epoch 51/100\n",
      "3781/3781 [==============================] - 3s 773us/sample - loss: 0.1145 - accuracy: 0.9352 - accuracy_1: 0.9352 - val_loss: 0.1179 - val_accuracy: 0.6219 - val_accuracy_1: 0.6560\n",
      "Epoch 52/100\n",
      "3781/3781 [==============================] - 3s 712us/sample - loss: 0.1145 - accuracy: 0.9259 - accuracy_1: 0.9259 - val_loss: 0.1177 - val_accuracy: 0.6354 - val_accuracy_1: 0.6759\n",
      "Epoch 53/100\n",
      "3781/3781 [==============================] - 3s 783us/sample - loss: 0.1145 - accuracy: 0.9283 - accuracy_1: 0.9283 - val_loss: 0.1176 - val_accuracy: 0.6469 - val_accuracy_1: 0.6880\n",
      "Epoch 54/100\n",
      "3781/3781 [==============================] - 3s 814us/sample - loss: 0.1146 - accuracy: 0.9254 - accuracy_1: 0.9254 - val_loss: 0.1173 - val_accuracy: 0.6594 - val_accuracy_1: 0.7005\n",
      "Epoch 55/100\n",
      "3781/3781 [==============================] - 3s 817us/sample - loss: 0.1145 - accuracy: 0.9336 - accuracy_1: 0.9336 - val_loss: 0.1177 - val_accuracy: 0.6396 - val_accuracy_1: 0.6778\n",
      "Epoch 56/100\n",
      "3781/3781 [==============================] - 3s 846us/sample - loss: 0.1145 - accuracy: 0.9294 - accuracy_1: 0.9294 - val_loss: 0.1181 - val_accuracy: 0.6167 - val_accuracy_1: 0.6537\n",
      "Epoch 57/100\n",
      "3781/3781 [==============================] - 3s 785us/sample - loss: 0.1145 - accuracy: 0.9257 - accuracy_1: 0.9257 - val_loss: 0.1174 - val_accuracy: 0.6458 - val_accuracy_1: 0.6944\n",
      "Epoch 58/100\n",
      "3781/3781 [==============================] - 3s 773us/sample - loss: 0.1146 - accuracy: 0.9209 - accuracy_1: 0.9209 - val_loss: 0.1176 - val_accuracy: 0.6396 - val_accuracy_1: 0.6708\n",
      "Epoch 59/100\n",
      "3781/3781 [==============================] - 3s 880us/sample - loss: 0.1144 - accuracy: 0.9368 - accuracy_1: 0.9368 - val_loss: 0.1176 - val_accuracy: 0.6490 - val_accuracy_1: 0.6958\n",
      "Epoch 60/100\n",
      "3781/3781 [==============================] - 3s 821us/sample - loss: 0.1145 - accuracy: 0.9214 - accuracy_1: 0.9214 - val_loss: 0.1173 - val_accuracy: 0.6802 - val_accuracy_1: 0.7005\n",
      "Epoch 61/100\n",
      "3781/3781 [==============================] - 3s 794us/sample - loss: 0.1146 - accuracy: 0.9196 - accuracy_1: 0.9196 - val_loss: 0.1176 - val_accuracy: 0.6698 - val_accuracy_1: 0.7028\n",
      "Epoch 62/100\n",
      "3781/3781 [==============================] - 3s 883us/sample - loss: 0.1145 - accuracy: 0.9249 - accuracy_1: 0.9249 - val_loss: 0.1177 - val_accuracy: 0.6417 - val_accuracy_1: 0.6486\n",
      "Epoch 63/100\n",
      "3781/3781 [==============================] - 3s 858us/sample - loss: 0.1146 - accuracy: 0.9172 - accuracy_1: 0.9172 - val_loss: 0.1173 - val_accuracy: 0.6802 - val_accuracy_1: 0.7074\n",
      "Epoch 64/100\n",
      "3781/3781 [==============================] - 3s 706us/sample - loss: 0.1146 - accuracy: 0.9051 - accuracy_1: 0.9051 - val_loss: 0.1176 - val_accuracy: 0.6760 - val_accuracy_1: 0.7032\n",
      "Epoch 65/100\n",
      "3781/3781 [==============================] - 2s 647us/sample - loss: 0.1146 - accuracy: 0.9177 - accuracy_1: 0.9177 - val_loss: 0.1173 - val_accuracy: 0.6542 - val_accuracy_1: 0.6773\n",
      "Epoch 66/100\n",
      "3781/3781 [==============================] - 3s 776us/sample - loss: 0.1146 - accuracy: 0.9230 - accuracy_1: 0.9230 - val_loss: 0.1174 - val_accuracy: 0.6812 - val_accuracy_1: 0.7102\n",
      "Epoch 67/100\n",
      "3781/3781 [==============================] - 3s 797us/sample - loss: 0.1145 - accuracy: 0.9278 - accuracy_1: 0.9278 - val_loss: 0.1175 - val_accuracy: 0.6771 - val_accuracy_1: 0.6991\n",
      "Epoch 68/100\n",
      "3781/3781 [==============================] - 3s 891us/sample - loss: 0.1146 - accuracy: 0.9188 - accuracy_1: 0.9188 - val_loss: 0.1171 - val_accuracy: 0.6958 - val_accuracy_1: 0.7074\n",
      "Epoch 69/100\n",
      "3781/3781 [==============================] - 3s 813us/sample - loss: 0.1146 - accuracy: 0.9214 - accuracy_1: 0.9214 - val_loss: 0.1170 - val_accuracy: 0.6802 - val_accuracy_1: 0.6773\n",
      "Epoch 70/100\n",
      "3781/3781 [==============================] - 3s 831us/sample - loss: 0.1145 - accuracy: 0.9249 - accuracy_1: 0.9249 - val_loss: 0.1171 - val_accuracy: 0.6823 - val_accuracy_1: 0.7130\n",
      "Epoch 71/100\n",
      "3781/3781 [==============================] - 3s 926us/sample - loss: 0.1145 - accuracy: 0.9347 - accuracy_1: 0.9347 - val_loss: 0.1172 - val_accuracy: 0.7063 - val_accuracy_1: 0.7144\n",
      "Epoch 72/100\n",
      "3781/3781 [==============================] - 3s 900us/sample - loss: 0.1145 - accuracy: 0.9254 - accuracy_1: 0.9254 - val_loss: 0.1176 - val_accuracy: 0.6646 - val_accuracy_1: 0.6981\n",
      "Epoch 73/100\n",
      "3781/3781 [==============================] - 4s 973us/sample - loss: 0.1145 - accuracy: 0.9389 - accuracy_1: 0.9389 - val_loss: 0.1177 - val_accuracy: 0.6365 - val_accuracy_1: 0.6764\n",
      "Epoch 74/100\n",
      "3781/3781 [==============================] - 4s 934us/sample - loss: 0.1146 - accuracy: 0.9183 - accuracy_1: 0.9183 - val_loss: 0.1178 - val_accuracy: 0.6260 - val_accuracy_1: 0.6833\n",
      "Epoch 75/100\n",
      "3781/3781 [==============================] - 4s 953us/sample - loss: 0.1147 - accuracy: 0.9135 - accuracy_1: 0.9135 - val_loss: 0.1176 - val_accuracy: 0.6438 - val_accuracy_1: 0.6819\n",
      "Epoch 76/100\n",
      "3781/3781 [==============================] - 3s 901us/sample - loss: 0.1145 - accuracy: 0.9196 - accuracy_1: 0.9196 - val_loss: 0.1173 - val_accuracy: 0.6552 - val_accuracy_1: 0.6986\n",
      "Epoch 77/100\n",
      "3781/3781 [==============================] - 4s 1ms/sample - loss: 0.1146 - accuracy: 0.9207 - accuracy_1: 0.9207 - val_loss: 0.1173 - val_accuracy: 0.6562 - val_accuracy_1: 0.6759\n",
      "Epoch 78/100\n",
      "3781/3781 [==============================] - 4s 1ms/sample - loss: 0.1146 - accuracy: 0.9328 - accuracy_1: 0.9328 - val_loss: 0.1173 - val_accuracy: 0.6698 - val_accuracy_1: 0.7120\n",
      "Epoch 79/100\n",
      "3781/3781 [==============================] - 4s 1ms/sample - loss: 0.1144 - accuracy: 0.9312 - accuracy_1: 0.9312 - val_loss: 0.1172 - val_accuracy: 0.6708 - val_accuracy_1: 0.7125\n",
      "Epoch 80/100\n",
      "3781/3781 [==============================] - 3s 865us/sample - loss: 0.1145 - accuracy: 0.9331 - accuracy_1: 0.9331 - val_loss: 0.1175 - val_accuracy: 0.6469 - val_accuracy_1: 0.6880\n",
      "Epoch 81/100\n",
      "3781/3781 [==============================] - 4s 961us/sample - loss: 0.1145 - accuracy: 0.9307 - accuracy_1: 0.9307 - val_loss: 0.1174 - val_accuracy: 0.6667 - val_accuracy_1: 0.6852\n",
      "Epoch 82/100\n",
      "3781/3781 [==============================] - 4s 955us/sample - loss: 0.1146 - accuracy: 0.9278 - accuracy_1: 0.9278 - val_loss: 0.1171 - val_accuracy: 0.6844 - val_accuracy_1: 0.7023\n",
      "Epoch 83/100\n",
      "3781/3781 [==============================] - 4s 942us/sample - loss: 0.1145 - accuracy: 0.9349 - accuracy_1: 0.9349 - val_loss: 0.1177 - val_accuracy: 0.6615 - val_accuracy_1: 0.6644\n",
      "Epoch 84/100\n",
      "3781/3781 [==============================] - 4s 938us/sample - loss: 0.1146 - accuracy: 0.9302 - accuracy_1: 0.9302 - val_loss: 0.1176 - val_accuracy: 0.6531 - val_accuracy_1: 0.7093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "3781/3781 [==============================] - 3s 758us/sample - loss: 0.1145 - accuracy: 0.9320 - accuracy_1: 0.9320 - val_loss: 0.1176 - val_accuracy: 0.6687 - val_accuracy_1: 0.6861\n",
      "Epoch 86/100\n",
      "3781/3781 [==============================] - 3s 877us/sample - loss: 0.1146 - accuracy: 0.9193 - accuracy_1: 0.9193 - val_loss: 0.1171 - val_accuracy: 0.6677 - val_accuracy_1: 0.7111\n",
      "Epoch 87/100\n",
      "3781/3781 [==============================] - 3s 870us/sample - loss: 0.1144 - accuracy: 0.9360 - accuracy_1: 0.9360 - val_loss: 0.1175 - val_accuracy: 0.6604 - val_accuracy_1: 0.6870\n",
      "Epoch 88/100\n",
      "3781/3781 [==============================] - 3s 690us/sample - loss: 0.1144 - accuracy: 0.9344 - accuracy_1: 0.9344 - val_loss: 0.1176 - val_accuracy: 0.6552 - val_accuracy_1: 0.6824\n",
      "Epoch 89/100\n",
      "3781/3781 [==============================] - 3s 720us/sample - loss: 0.1146 - accuracy: 0.9212 - accuracy_1: 0.9212 - val_loss: 0.1173 - val_accuracy: 0.6365 - val_accuracy_1: 0.6741\n",
      "Epoch 90/100\n",
      "3781/3781 [==============================] - 3s 876us/sample - loss: 0.1148 - accuracy: 0.9045 - accuracy_1: 0.9045 - val_loss: 0.1172 - val_accuracy: 0.6531 - val_accuracy_1: 0.6838\n",
      "Epoch 91/100\n",
      "3781/3781 [==============================] - 3s 902us/sample - loss: 0.1145 - accuracy: 0.9320 - accuracy_1: 0.9320 - val_loss: 0.1176 - val_accuracy: 0.6365 - val_accuracy_1: 0.6833\n",
      "Epoch 92/100\n",
      "3781/3781 [==============================] - 3s 821us/sample - loss: 0.1145 - accuracy: 0.9344 - accuracy_1: 0.9344 - val_loss: 0.1178 - val_accuracy: 0.6438 - val_accuracy_1: 0.6935\n",
      "Epoch 93/100\n",
      "3781/3781 [==============================] - 3s 726us/sample - loss: 0.1145 - accuracy: 0.9339 - accuracy_1: 0.9339 - val_loss: 0.1177 - val_accuracy: 0.6271 - val_accuracy_1: 0.6838\n",
      "Epoch 94/100\n",
      "3781/3781 [==============================] - 3s 727us/sample - loss: 0.1145 - accuracy: 0.9289 - accuracy_1: 0.9289 - val_loss: 0.1175 - val_accuracy: 0.6302 - val_accuracy_1: 0.6875\n",
      "Epoch 95/100\n",
      "3781/3781 [==============================] - 4s 964us/sample - loss: 0.1145 - accuracy: 0.9204 - accuracy_1: 0.9204 - val_loss: 0.1176 - val_accuracy: 0.6573 - val_accuracy_1: 0.6856\n",
      "Epoch 96/100\n",
      "3781/3781 [==============================] - 3s 852us/sample - loss: 0.1144 - accuracy: 0.9331 - accuracy_1: 0.9331 - val_loss: 0.1174 - val_accuracy: 0.6698 - val_accuracy_1: 0.6912\n",
      "Epoch 97/100\n",
      "3781/3781 [==============================] - 3s 802us/sample - loss: 0.1145 - accuracy: 0.9267 - accuracy_1: 0.9267 - val_loss: 0.1178 - val_accuracy: 0.6365 - val_accuracy_1: 0.6856\n",
      "Epoch 98/100\n",
      "3781/3781 [==============================] - 3s 826us/sample - loss: 0.1144 - accuracy: 0.9236 - accuracy_1: 0.9236 - val_loss: 0.1177 - val_accuracy: 0.6646 - val_accuracy_1: 0.7097\n",
      "Epoch 99/100\n",
      "3781/3781 [==============================] - 3s 777us/sample - loss: 0.1144 - accuracy: 0.9466 - accuracy_1: 0.9466 - val_loss: 0.1176 - val_accuracy: 0.6979 - val_accuracy_1: 0.6921\n",
      "Epoch 100/100\n",
      "3781/3781 [==============================] - 3s 913us/sample - loss: 0.1146 - accuracy: 0.9207 - accuracy_1: 0.9207 - val_loss: 0.1180 - val_accuracy: 0.6042 - val_accuracy_1: 0.6551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f38a8314c10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "#     loss='categorical_crossentropy', \n",
    "    loss= focal_loss([600,3600,600],gamma=5, alpha=.25),\n",
    "              optimizer='Adam', metrics=['accuracy'],\n",
    "              weighted_metrics=['accuracy'])\n",
    "earlier = EarlyStopping(monitor = 'val_accuracy',mode='max',min_delta=1e-3,patience=50,verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath='best.hdf5',verbose=1, save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "\n",
    "# class_weight = {0 : 2., 1: 5.,2:1.}\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=50,\n",
    "#           class_weight=class_weight)\n",
    "          validation_data=(X_val, Y_val,val_sample_weights)\n",
    "#           callbacks=[earlier, checkpointer])\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# model.load_weights('best.hdf5')\n",
    "model.save_weights('my_model_weights_mixed_2.h5')\n",
    "Y_test = model.predict_classes(X_test)\n",
    "print(Y_test)\n",
    "\n",
    "\n",
    "f = open(\"best_focal_mixed_3.csv\", \"w\")\n",
    "f.write(\"id,y\\n\")\n",
    "for i,x in enumerate(Y_test):\n",
    "    f.write(\"{},{}\\n\".format(i,x))\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# try subsampling\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def sub_sampling(sampling_strategy_over,sampling_strategy_down,x_train,y_train):\n",
    "    model_smote = SMOTE(sampling_strategy_over)\n",
    "    model_RandomUnderSampler = RandomUnderSampler(sampling_strategy_down) \n",
    "    \n",
    "    x_sample_train, y_sample_train = model_smote.fit_sample(x_train,y_train)\n",
    "    x_sample_train, y_sample_train =model_RandomUnderSampler.fit_sample(x_sample_train,y_sample_train)\n",
    "\n",
    "    print('After sub-sampling:\\n',pd.DataFrame(y_sample_train,columns=['y']).groupby('y').size())\n",
    "    return x_sample_train,y_sample_train\n",
    "\n",
    "sampling_strategy_over = {0:1000,2:1000}\n",
    "sampling_strategy_down = {1:1000}\n",
    "x_sample_train,y_sample_train = sub_sampling(sampling_strategy_over,sampling_strategy_down,x_train,y_train)\n",
    "\n",
    "model = create_model(\n",
    "             activation1='relu',activation2='sigmoid',\n",
    "             d=0.5,n1=1024,n2=1512,n3=1512,n4=1024,n5=768,n6=256,n7=3)\n",
    "\n",
    "model.fit(x_sample_train,y_sample_train, epochs=200, batch_size=90, validation_data=(X_val, Y_val,val_sample_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# model.load_weights('best.hdf5')\n",
    "Y_test = model.predict_classes(X_test)\n",
    "print(Y_test)\n",
    "\n",
    "\n",
    "f = open(\"best_subs.csv\", \"w\")\n",
    "f.write(\"id,y\\n\")\n",
    "for i,x in enumerate(Y_test):\n",
    "    f.write(\"{},{}\\n\".format(i,x))\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# random search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Specify parameters and distributions to sample from\n",
    "n1 = [512,768,1024,1512,2048]\n",
    "n2 = [256,512,768,1024,1512,2048,2560]\n",
    "n3 = [256,512,768,1024,1512,2048,2560]\n",
    "n4 = [128,256,512,768,1024,1512]\n",
    "n5 = [128,256,512,768,1024,1512]\n",
    "n6 = [64,128,256,512,768]\n",
    "n7 = [3]\n",
    "# batch_size = [32, 64, 96, 128, 256]\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam']\n",
    "# learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "activation1 = ['softplus', 'relu','exponential']\n",
    "activation2 = ['softmax', 'softsign', 'tanh', 'sigmoid']\n",
    "dropout_rate = [0.2, 0.5, 0.8]\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model)             \n",
    "#     loss=focal_loss(alpha=1),\n",
    "#              optimizer='Adam',\n",
    "#              activation1='relu',activation2='softmax',\n",
    "#              d=0.5,n1=1024,n2=1512,n3=1512,n4=1024,n5=768,n6=256,n7=3),\n",
    "#                         epochs=200, batch_size=90))\n",
    "                        # , validation_data=(X_val, Y_val,val_sample_weights))\n",
    "                        # ,batch_size =batch_size,learn_rate=learn_rate)\n",
    "   \n",
    "# Prepare the Dict for the Search\n",
    "param_dist = dict(\n",
    "                n1 = n1,\n",
    "                n2 = n2,\n",
    "                n3 = n3,\n",
    "                n4 = n4,\n",
    "                n5 = n5,\n",
    "                n6 = n6,\n",
    "                n7 = n7,\n",
    "#                 # batch_size = batch_size,\n",
    "                optimizer = optimizer,\n",
    "#                 # learn_rate = learn_rate,\n",
    "                activation1 = activation1,\n",
    "                activation2 = activation2,\n",
    "                d = dropout_rate,\n",
    "                loss=[focal_loss([600,3600,600])])\n",
    "\n",
    "# Search in action!\n",
    "n_iter_search = 5000 # Number of parameter settings that are sampled.\n",
    "random_search = RandomizedSearchCV(estimator=model, \n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   n_jobs=-1, \n",
    "\t\t\t\t\t\t\t\t   cv=5, \n",
    "\t\t\t\t\t\t\t\t   verbose=1)\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "# Show the results\n",
    "print(\"Best: %f using %s\" % (random_search.best_score_, random_search.best_params_))\n",
    "means = random_search.cv_results_['mean_test_score']\n",
    "stds = random_search.cv_results_['std_test_score']\n",
    "params = random_search.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "0.0312 - val_weighted_acc: 0.0588\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "BMAC = balanced_accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
