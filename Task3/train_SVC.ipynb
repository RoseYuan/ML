{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading https://files.pythonhosted.org/packages/81/a7/4179e6ebfd654bd0eac0b9c06125b8b4c96a9d0a8ff9e9507eb2a26d2d7e/imblearn-0.0-py2.py3-none-any.whl\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Using cached https://files.pythonhosted.org/packages/e6/62/08c14224a7e242df2cef7b312d2ef821c3931ec9b015ff93bb52ec8a10a3/imbalanced_learn-0.5.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.11 in /local/bin/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.17.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21 in /local/bin/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.21.3)\n",
      "Requirement already satisfied: scipy>=0.17 in /local/bin/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /local/bin/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.13.2)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.5.0 imblearn-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_files = [\"train_RRI_features.csv\", \"train_templ_features.csv\",\"train_P_hr_features.csv\"]\n",
    "test_feature_files = [\"test_RRI_features.csv\", \"test_templ_features.csv\",\"test_P_hr_features.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    print(\"Load the data.\")\n",
    "    global y_train\n",
    "    global x_train\n",
    "    global x_test\n",
    "    \n",
    "    df_x_train = pd.concat(map(pd.read_csv, train_feature_files),axis=1)\n",
    "    df_x_test = pd.concat(map(pd.read_csv, test_feature_files),axis=1)\n",
    "    df_y_train = pd.read_csv(\"y_train.csv\")\n",
    "\n",
    "    x_test = df_x_test.values[:,1:]\n",
    "    x_train = df_x_train.values[:,1:]\n",
    "    y_train = df_y_train['y'].values\n",
    "    \n",
    "    print('Standardize the data.')\n",
    "    scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "    \n",
    "    x_train =scaler.transform(x_train)\n",
    "    \n",
    "    x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the data.\n",
      "Standardize the data.\n",
      "There are 0 NAN values.\n"
     ]
    }
   ],
   "source": [
    "# pd.read_csv(\"test_RRI_features.csv\")\n",
    "load_data()\n",
    "x_test\n",
    "print('There are %d NAN values.'%np.sum(np.isnan(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "Load the data.\n",
      "Standardize the data.\n",
      "predicted y: [0 0 0 ... 0 0 1]\n",
      "C value: 5.600000\n",
      "Cross validation score:0.778613\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# F1 = f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "n=20\n",
    "\n",
    "# Cvalues = [3,4,5,6,7,8,9,10]\n",
    "# Cvalues = [5,5.2,5.4,5.6,5.8,6]\n",
    "\n",
    "def train(C):\n",
    "    val_result = []\n",
    "\n",
    "    for i in range(n):\n",
    "        load_data()\n",
    "        np.random.seed(i)\n",
    "        \n",
    "#         model_RandomUnderSampler = RandomUnderSampler()\n",
    "#         x_train_t, y_train_t =model_RandomUnderSampler.fit_sample(x_train,y_train)\n",
    "#         print('After down-sampling:\\n',pd.DataFrame(y_train_t,columns=['y']).groupby('y').size())\n",
    "        \n",
    "        x_train_t = x_train\n",
    "        y_train_t = y_train\n",
    "\n",
    "        x_train_t, x_val_t, y_train_t, y_val_t = train_test_split(x_train_t, y_train_t, test_size=0.1)\n",
    "\n",
    "        clf = SVC(kernel='rbf',C=C, \n",
    "        decision_function_shape='ovr',  gamma='auto',\n",
    "        max_iter=-1, probability=False, shrinking=True,\n",
    "        tol=0.001, verbose=False,random_state=i,class_weight=None)   # add class weight\n",
    "\n",
    "        clf.fit(x_train_t, y_train_t)\n",
    "\n",
    "        y_val_p = clf.predict(x_val_t)\n",
    "        val_result.append(f1_score(y_val_t, y_val_p, average='micro'))\n",
    "\n",
    "        y_pred = clf.predict(x_test)\n",
    "        print(\"predicted y:\",y_pred)\n",
    "\n",
    "        f = open(\"submission_svc{0:.1f}.csv\".format(i), \"w\")\n",
    "        f.write(\"id,y\\n\")\n",
    "        for i,x in enumerate(y_pred):\n",
    "            f.write(\"{},{}\\n\".format(i,x))\n",
    "        f.close()\n",
    "\n",
    "    print(\"C value: %f\\nCross validation score:%f\"%(C,np.mean(val_result)))\n",
    "\n",
    "# for C in Cvalues:\n",
    "#     train(C)\n",
    "train(5.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "size = x_test.shape\n",
    "result = [list() for i in range(size[0])]\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "    f = \"submission_svc%d.0.csv\" %(i)\n",
    "    f = open(f)\n",
    "    lines = f.readlines()\n",
    "    for l in lines[1:]:\n",
    "        l = l.strip().split(',')\n",
    "        idx, val = int(l[0]), int(float(l[1]))\n",
    "        result[idx].append(val)\n",
    "    f.close()\n",
    "print(result[:20])\n",
    "\n",
    "\n",
    "def vote(x):\n",
    "    c = [0] * 4\n",
    "    for i in x:\n",
    "        c[i] += 1\n",
    "    c = [(0, c[0]), (1, c[1]), (2, c[2])]\n",
    "    c.sort(key = lambda x: x[1], reverse = True)\n",
    "    if c[0][1] > c[1][1]:\n",
    "        return c[0][0]\n",
    "    else:\n",
    "        if c[0][0] == 1 or c[1][0] == 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return np.random.choice([c[0][0], c[1][0]])\n",
    "print(vote([1,2,0,0,0]))\n",
    "\n",
    "\n",
    "with open(\"voted_svc.csv\", \"w\") as f:\n",
    "    f.write(\"id,y\\n\")\n",
    "    for i in range(size[0]):\n",
    "        f.write(\"{},{}\\n\".format(i, vote(result[i])))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
