{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data\n",
    "df_X = pd.read_csv('./data/X_train.csv')\n",
    "df_y = pd.read_csv('./data/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5117, 17813)\n",
      "(5117,)\n"
     ]
    }
   ],
   "source": [
    "# convert into np array, check shape\n",
    "X_raw = np.array(df_X)[:, 1:]\n",
    "print(X_raw.shape)\n",
    "\n",
    "y_raw = np.array(df_y, dtype=int)[:, 1]\n",
    "print(y_raw.shape)\n",
    "\n",
    "num_samples = X_raw.shape[0]\n",
    "num_features = X_raw.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frames no longer needed\n",
    "del df_X, df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the dataset\n",
    "X_raw, y_raw = shuffle(X_raw, y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-450. -436. -426. ... 3094. 2890. 2681.]\n"
     ]
    }
   ],
   "source": [
    "# recordings trimmed of NaNs\n",
    "recordings = []\n",
    "for i in range(X_raw.shape[0]):\n",
    "    recordings.append(X_raw[i, ~np.isnan(X_raw[i,:])])\n",
    "\n",
    "print(recordings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset augmented by repetition\n",
    "def augmentation(X):\n",
    "    augmented = np.copy(X)\n",
    "    for i in range(X.shape[0]):\n",
    "        n = 17813\n",
    "        for j in range(X.shape[1]):\n",
    "            if np.isnan(X[i,j]):\n",
    "                n = j\n",
    "                break\n",
    "        for j in range(n, X.shape[1]):\n",
    "            augmented[i,j] = X[i, j%n]\n",
    "        \n",
    "    return augmented\n",
    "\n",
    "X_augmented = augmentation(X_raw)\n",
    "\n",
    "# make sure no more NaN exists\n",
    "np.sum(np.isnan(X_augmented))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_augmented[0:5000, :]\n",
    "X_validation = X_augmented[5000:, :]\n",
    "y_train = y_raw[0:5000]\n",
    "y_validation = y_raw[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check group balance\n",
    "print(np.sum(y_train == 0), np.sum(y_train == 1), np.sum(y_train == 2), np.sum(y_train == 3))\n",
    "print(np.sum(y_validation == 0), np.sum(y_validation == 1), np.sum(y_validation == 2), np.sum(y_validation == 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamic time warpping -- too slow to be used\n",
    "def constrained_dtw(t1, t2, w=float('inf'), matrix=False):\n",
    "    n1 = len(t1)\n",
    "    n2 = len(t2)\n",
    "    if w < abs(n1 - n2):\n",
    "        print('ERROR: constraint smaller than difference in length.')\n",
    "        exit(1)\n",
    "    \n",
    "    # distance matrix with infinity for all entries\n",
    "    dist_matrix = np.ones((n1+1, n2+1)) * float('inf')\n",
    "    dist_matrix[0,0] = 0\n",
    "    \n",
    "    # distance within the contrained range\n",
    "    for i in range(n1):\n",
    "        for j in range(n2): \n",
    "            if abs(i-j) <= w:\n",
    "                dist_matrix[i+1,j+1] = abs(t1[i] - t2[j]) + min(dist_matrix[i,j], dist_matrix[i+1,j], dist_matrix[i,j+1])\n",
    "    \n",
    "    if matrix: \n",
    "        return dist_matrix\n",
    "    else:\n",
    "        return dist_matrix[n1,n2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([np.sin(x*0.5) for x in range(100)])\n",
    "#plt.plot(a)\n",
    "plt.plot(np.fft.rfft(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.ylim(-2048, 2048)\n",
    "\n",
    "n1 = 2\n",
    "plt.plot(recordings[n1])\n",
    "plt.show()\n",
    "print('class:', y_raw[n1])\n",
    "print('mean:', np.mean(recordings[n1]))\n",
    "print('variance:', np.var(recordings[n1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biosppy.signals import ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5117/5117 [01:17<00:00, 66.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# extract R peaks\n",
    "peaks = []\n",
    "for i in tqdm(range(len(recordings))): \n",
    "    out = ecg.hamilton_segmenter(signal=recordings[i], sampling_rate=300)\n",
    "    peaks.append(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2469\n",
      "5\n",
      "4769\n",
      "158\n"
     ]
    }
   ],
   "source": [
    "# find least and greatest number of peaks\n",
    "least = len(peaks[0])\n",
    "least_id = 0\n",
    "most = len(peaks[0])\n",
    "most_id = 0\n",
    "\n",
    "for i in range(1,len(peaks)):\n",
    "    if len(peaks[i]) < least:\n",
    "        least = len(peaks[i])\n",
    "        least_id = i\n",
    "    if len(peaks[i]) > most:\n",
    "        most = len(peaks[i])\n",
    "        most_id = i\n",
    "\n",
    "print(least_id)\n",
    "print(least)\n",
    "print(most_id)\n",
    "print(most)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2917"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recordings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "781.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recordings[0][327]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5117/5117 [00:00<00:00, 6928.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# augmentation\n",
    "neighbourhood = 50\n",
    "subsampling = 1\n",
    "X_2d = np.zeros((len(peaks), most, 2*neighbourhood//subsampling))\n",
    "for i in tqdm(range(len(peaks))):\n",
    "    count = 0\n",
    "    length = len(recordings[i])\n",
    "    for r in peaks[i]:\n",
    "        if r >= neighbourhood and r < length - neighbourhood:\n",
    "            X_2d[i,count,:] = recordings[i][r-neighbourhood : r+neighbourhood : subsampling]\n",
    "            count += 1\n",
    "    \n",
    "    for j in range(count, most):\n",
    "        X_2d[i,j,:] = X_2d[i,j%count,:]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe43942d410>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(X_2d[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n",
    "    c3 = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    # if c3 == 0:\n",
    "    #     return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 154, 32)           5152      \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 150, 32)           5152      \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 146, 32)           5152      \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 142, 32)           5152      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 30,084\n",
      "Trainable params: 30,084\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kernel_size = least\n",
    "num_filters = 32\n",
    "width = 2*neighbourhood // subsampling\n",
    "\n",
    "model_1d = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Input(shape=(most, width)),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(kernel_size=kernel_size, filters=num_filters, activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(kernel_size=kernel_size, filters=num_filters, activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(kernel_size=kernel_size, filters=num_filters, activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(kernel_size=kernel_size, filters=num_filters, activation='relu'),\n",
    "        tf.keras.layers.GlobalMaxPooling1D(),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        \n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        \n",
    "        tf.keras.layers.Dense(4, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_1d.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_score])\n",
    "model_1d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_9 (Reshape)          (None, 158, 32, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 154, 28, 32)       832       \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 150, 24, 32)       25632     \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 146, 20, 32)       25632     \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 93440)             0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 256)               23920896  \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 23,974,020\n",
      "Trainable params: 23,974,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kernel_size = least\n",
    "num_filters = 32\n",
    "width = 2*neighbourhood // subsampling\n",
    "\n",
    "model_2d = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Reshape(input_shape=(most, width), target_shape=(most, width, 1)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(kernel_size=least, filters=num_filters, activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(kernel_size=least, filters=num_filters, activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(kernel_size=least, filters=num_filters, activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.GlobalMaxPooling2D(),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        \n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        \n",
    "        tf.keras.layers.Dense(4, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_2d.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_score])\n",
    "model_2d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5117, 158, 32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2948 431 1452 169\n",
      "82 12 22 1\n"
     ]
    }
   ],
   "source": [
    "X_train = X_2d[:5000]\n",
    "X_validation = X_2d[5000:]\n",
    "y_train = y_raw[:5000]\n",
    "y_validation = y_raw[5000:]\n",
    "\n",
    "y_target = tf.keras.utils.to_categorical(y_train)\n",
    "validation_dataset = (X_validation, tf.keras.utils.to_categorical(y_validation))\n",
    "\n",
    "# check group balance\n",
    "print(np.sum(y_train == 0), np.sum(y_train == 1), np.sum(y_train == 2), np.sum(y_train == 3))\n",
    "print(np.sum(y_validation == 0), np.sum(y_validation == 1), np.sum(y_validation == 2), np.sum(y_validation == 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 117 samples\n",
      "Epoch 1/32\n",
      "5000/5000 [==============================] - 54s 11ms/sample - loss: 24.1387 - accuracy: 0.5746 - f1_score: nan - val_loss: 1.0309 - val_accuracy: 0.7009 - val_f1_score: nan\n",
      "Epoch 2/32\n",
      "5000/5000 [==============================] - 53s 11ms/sample - loss: 1.0501 - accuracy: 0.5896 - f1_score: nan - val_loss: 0.9103 - val_accuracy: 0.7009 - val_f1_score: 0.6979\n",
      "Epoch 3/32\n",
      "5000/5000 [==============================] - 52s 10ms/sample - loss: 1.0087 - accuracy: 0.5896 - f1_score: 0.5812 - val_loss: 0.8898 - val_accuracy: 0.7009 - val_f1_score: 0.6979\n",
      "Epoch 4/32\n",
      "5000/5000 [==============================] - 53s 11ms/sample - loss: 1.0022 - accuracy: 0.5896 - f1_score: 0.5818 - val_loss: 0.8904 - val_accuracy: 0.7009 - val_f1_score: 0.6979\n",
      "Epoch 5/32\n",
      "4064/5000 [=======================>......] - ETA: 10s - loss: 1.0045 - accuracy: 0.5868 - f1_score: 0.5820"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-e52123be2598>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           validation_data=validation_dataset)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model_2d\n",
    "model.fit(x=X_train,\n",
    "          y=y_target,\n",
    "          batch_size=32, \n",
    "          epochs=32, \n",
    "          validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./data/X_test.csv')\n",
    "X_test = np.array(df_test)[:,1:]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_augmented = augmentation(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = model.predict(X_test[:,0:15000:5])\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.argmax(y_test, axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write output csv\n",
    "out_df = pd.DataFrame(data={'y': result})\n",
    "out_df.to_csv('result4.csv', index_label='id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
